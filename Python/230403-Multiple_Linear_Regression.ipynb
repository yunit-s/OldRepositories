{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "297912d2",
   "metadata": {},
   "source": [
    "## 다중 선형 회귀\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5b51b5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중 선형 회귀\n",
    "\n",
    "# 오존 데이터 활용\n",
    "\n",
    "# 1. 필요한 module 불러들이기\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# scikit-learn\n",
    "#     모델을 쉽게 다룰 수 있을 뿐만 아니라 데이터 핸들링에서도 도움이 된다.\n",
    "#     데이터 정규화하는 데 사용할 예정\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# optimizer\n",
    "#     w와 b를 수정하기 위한 옵티마이저\n",
    "#     SGD : Gredient Descent의 다음 버전. 좋은 건 아닌데, 그래도 좋아진 버전\n",
    "#     Adam\n",
    "#         옵티마이저들의 장점들만 모아놓은 버전. 사람들이 많이 사용한다.\n",
    "# 그림은 못 그려. 데이터가 4차원이라서. 그래서 그래프 그리는 건 패스\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "273cef44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ozone</th>\n",
       "      <th>Solar.R</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>67</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>72</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>74</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>62</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.3</td>\n",
       "      <td>56</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ozone  Solar.R  Wind  Temp  Month  Day\n",
       "0   41.0    190.0   7.4    67      5    1\n",
       "1   36.0    118.0   8.0    72      5    2\n",
       "2   12.0    149.0  12.6    74      5    3\n",
       "3   18.0    313.0  11.5    62      5    4\n",
       "4    NaN      NaN  14.3    56      5    5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(153, 6)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ozone</th>\n",
       "      <th>Solar.R</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>67</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>72</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>74</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>62</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>65</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ozone  Solar.R  Wind  Temp  Month  Day\n",
       "0   41.0    190.0   7.4    67      5    1\n",
       "1   36.0    118.0   8.0    72      5    2\n",
       "2   12.0    149.0  12.6    74      5    3\n",
       "3   18.0    313.0  11.5    62      5    4\n",
       "6   23.0    299.0   8.6    65      5    7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(111, 6)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Raw Data Loading\n",
    "raw_data = pd.read_csv('./data/ozone.csv')\n",
    "display(raw_data.head(), raw_data.shape) # 출력 : (153, 6)\n",
    "\n",
    "# 결측치 처리 => 그냥 삭제하자.\n",
    "raw_data = raw_data.dropna(how='any')\n",
    "display(raw_data.head(), raw_data.shape) # 출력 : (111, 6)\n",
    "\n",
    "# 이상치는 반드시 처리를 해야 전체 데이터가 안 망가지는데, 일단은 처리하지 말자.\n",
    "\n",
    "# 정규화\n",
    "#     MinMaxScaling으로 진행하기\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_t = MinMaxScaler()\n",
    "\n",
    "# scaler한테 최댓값과 최솟값을 알려줘야 이 놈이 정보를 가지고 정규화를 진행한다.\n",
    "scaler_x.fit(raw_data[['Solar.R', 'Wind', 'Temp']].values)\n",
    "scaler_t.fit(raw_data['Ozone'].values.reshape(-1, 1))\n",
    "#     scaler에게 정보를 줄 때는 2차원 matrix로 줘야 한다.\n",
    "#     단순히 ['Ozone'] 이라고만 하면 Series 라서 reshape을 해줘야하는 것\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e888ad6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.55963303 0.27717391 0.25      ]\n",
      " [0.33944954 0.30978261 0.375     ]\n",
      " [0.43425076 0.55978261 0.425     ]\n",
      " [0.93577982 0.5        0.125     ]\n",
      " [0.89296636 0.3423913  0.2       ]\n",
      " [0.28134557 0.625      0.05      ]\n",
      " [0.03669725 0.9673913  0.1       ]\n",
      " [0.76146789 0.40217391 0.3       ]\n",
      " [0.86544343 0.375      0.225     ]\n",
      " [0.81651376 0.4673913  0.275     ]\n",
      " [0.17737003 0.5923913  0.025     ]\n",
      " [1.         0.5        0.175     ]\n",
      " [0.91743119 0.52717391 0.225     ]\n",
      " [0.21712538 0.875      0.        ]\n",
      " [0.96330275 0.5        0.275     ]\n",
      " [0.11314985 0.40217391 0.125     ]\n",
      " [0.0030581  0.40217391 0.05      ]\n",
      " [0.95718654 0.77717391 0.4       ]\n",
      " [0.05504587 0.40217391 0.1       ]\n",
      " [0.25993884 0.52717391 0.1       ]\n",
      " [0.01834862 0.52717391 0.25      ]\n",
      " [0.74923547 0.68478261 0.6       ]\n",
      " [0.66055046 0.18478261 0.55      ]\n",
      " [0.83180428 0.27717391 0.475     ]\n",
      " [0.36697248 0.40217391 0.625     ]\n",
      " [0.86850153 0.625      0.825     ]\n",
      " [0.96636086 0.5        0.75      ]\n",
      " [0.43119266 0.30978261 0.625     ]\n",
      " [0.56269113 0.68478261 0.5       ]\n",
      " [0.8470948  1.         0.375     ]\n",
      " [0.09174312 0.375      0.2       ]\n",
      " [0.34556575 0.5        0.4       ]\n",
      " [0.39755352 0.43478261 0.475     ]\n",
      " [0.80122324 0.09782609 0.675     ]\n",
      " [0.73700306 0.375      0.7       ]\n",
      " [0.70030581 0.375      0.6       ]\n",
      " [0.51376147 0.125      0.65      ]\n",
      " [0.93883792 0.4673913  0.65      ]\n",
      " [0.82262997 0.15217391 0.775     ]\n",
      " [0.79510703 0.2173913  0.875     ]\n",
      " [0.81039755 0.18478261 0.875     ]\n",
      " [0.51376147 0.27717391 0.8       ]\n",
      " [0.78593272 0.65217391 0.4       ]\n",
      " [0.51376147 0.68478261 0.6       ]\n",
      " [0.12538226 0.65217391 0.575     ]\n",
      " [0.77370031 0.25       0.6       ]\n",
      " [0.81651376 0.43478261 0.625     ]\n",
      " [0.85015291 0.2173913  0.675     ]\n",
      " [0.55045872 0.15217391 0.75      ]\n",
      " [0.65137615 0.5        0.7       ]\n",
      " [0.         0.25       0.425     ]\n",
      " [0.87767584 0.3423913  0.725     ]\n",
      " [0.66055046 0.30978261 0.7       ]\n",
      " [0.22629969 0.3423913  0.625     ]\n",
      " [0.2293578  0.52717391 0.725     ]\n",
      " [0.62996942 0.27717391 0.775     ]\n",
      " [0.81957187 0.27717391 0.725     ]\n",
      " [0.75229358 0.27717391 0.65      ]\n",
      " [0.75535168 0.375      0.6       ]\n",
      " [0.2324159  0.25       0.6       ]\n",
      " [0.05198777 0.625      0.6       ]\n",
      " [0.21406728 0.27717391 0.625     ]\n",
      " [0.75840979 0.0923913  0.8       ]\n",
      " [0.67889908 0.43478261 0.825     ]\n",
      " [0.6116208  0.30978261 0.825     ]\n",
      " [0.56574924 0.5        0.725     ]\n",
      " [0.81345566 0.5        0.625     ]\n",
      " [0.4587156  0.40217391 0.575     ]\n",
      " [0.19571865 0.43478261 0.5       ]\n",
      " [0.13455657 0.2173913  0.55      ]\n",
      " [0.33027523 0.27717391 0.475     ]\n",
      " [0.72477064 0.4673913  0.525     ]\n",
      " [0.55963303 0.43478261 0.525     ]\n",
      " [0.7706422  0.7173913  0.5       ]\n",
      " [0.08868502 0.65217391 0.375     ]\n",
      " [0.62691131 0.40217391 0.55      ]\n",
      " [0.70642202 0.05978261 0.6       ]\n",
      " [0.63608563 0.30978261 0.725     ]\n",
      " [0.59938838 0.40217391 1.        ]\n",
      " [0.66666667 0.         0.925     ]\n",
      " [0.70336391 0.2173913  0.975     ]\n",
      " [0.55351682 0.2173913  0.925     ]\n",
      " [0.48929664 0.25       0.85      ]\n",
      " [0.58103976 0.15217391 0.875     ]\n",
      " [0.5382263  0.02717391 0.9       ]\n",
      " [0.55657492 0.125      0.9       ]\n",
      " [0.26911315 0.27717391 0.75      ]\n",
      " [0.25993884 0.7173913  0.675     ]\n",
      " [0.74923547 0.4673913  0.575     ]\n",
      " [0.65137615 0.43478261 0.525     ]\n",
      " [0.68195719 0.4673913  0.45      ]\n",
      " [0.7706422  0.40217391 0.4       ]\n",
      " [0.70030581 0.68478261 0.6       ]\n",
      " [0.7706422  0.7173913  0.475     ]\n",
      " [0.70642202 0.2173913  0.5       ]\n",
      " [0.05198777 0.4673913  0.35      ]\n",
      " [0.32110092 0.5        0.35      ]\n",
      " [0.70336391 0.25       0.525     ]\n",
      " [0.66360856 0.625      0.25      ]\n",
      " [0.06116208 0.43478261 0.475     ]\n",
      " [0.70642202 0.43478261 0.275     ]\n",
      " [0.59327217 0.30978261 0.625     ]\n",
      " [0.70642202 0.55978261 0.175     ]\n",
      " [0.02140673 0.375      0.35      ]\n",
      " [0.40366972 0.43478261 0.6       ]\n",
      " [0.12844037 0.43478261 0.3       ]\n",
      " [0.03975535 0.77717391 0.15      ]\n",
      " [0.56880734 0.25       0.325     ]\n",
      " [0.56269113 0.65217391 0.45      ]\n",
      " [0.37920489 0.30978261 0.475     ]\n",
      " [0.66055046 0.5        0.275     ]]\n",
      "[[0.23952096]\n",
      " [0.20958084]\n",
      " [0.06586826]\n",
      " [0.10179641]\n",
      " [0.13173653]\n",
      " [0.10778443]\n",
      " [0.04191617]\n",
      " [0.08982036]\n",
      " [0.05988024]\n",
      " [0.07784431]\n",
      " [0.10179641]\n",
      " [0.07784431]\n",
      " [0.19760479]\n",
      " [0.02994012]\n",
      " [0.17365269]\n",
      " [0.05988024]\n",
      " [0.        ]\n",
      " [0.05988024]\n",
      " [0.01796407]\n",
      " [0.18562874]\n",
      " [0.13173653]\n",
      " [0.26347305]\n",
      " [0.68263473]\n",
      " [0.21556886]\n",
      " [0.16766467]\n",
      " [0.41916168]\n",
      " [0.22754491]\n",
      " [0.13173653]\n",
      " [0.11976048]\n",
      " [0.21556886]\n",
      " [0.11377246]\n",
      " [0.06586826]\n",
      " [0.07185629]\n",
      " [0.80239521]\n",
      " [0.28742515]\n",
      " [0.18562874]\n",
      " [0.37724551]\n",
      " [0.23353293]\n",
      " [0.45508982]\n",
      " [0.5748503 ]\n",
      " [0.5748503 ]\n",
      " [0.50299401]\n",
      " [0.05389222]\n",
      " [0.15568862]\n",
      " [0.03592814]\n",
      " [0.28143713]\n",
      " [0.20359281]\n",
      " [0.35928144]\n",
      " [0.46706587]\n",
      " [0.37125749]\n",
      " [0.08982036]\n",
      " [0.47305389]\n",
      " [0.64071856]\n",
      " [0.11377246]\n",
      " [0.30538922]\n",
      " [0.48502994]\n",
      " [0.29341317]\n",
      " [0.37724551]\n",
      " [0.34730539]\n",
      " [0.22754491]\n",
      " [0.04790419]\n",
      " [0.08982036]\n",
      " [0.7245509 ]\n",
      " [0.52694611]\n",
      " [0.65269461]\n",
      " [0.25748503]\n",
      " [0.16167665]\n",
      " [0.38323353]\n",
      " [0.1257485 ]\n",
      " [0.34730539]\n",
      " [0.13173653]\n",
      " [0.17964072]\n",
      " [0.25748503]\n",
      " [0.11976048]\n",
      " [0.04790419]\n",
      " [0.26347305]\n",
      " [1.        ]\n",
      " [0.43113772]\n",
      " [0.4491018 ]\n",
      " [0.7005988 ]\n",
      " [0.49700599]\n",
      " [0.50299401]\n",
      " [0.56886228]\n",
      " [0.46107784]\n",
      " [0.43113772]\n",
      " [0.53892216]\n",
      " [0.2754491 ]\n",
      " [0.18562874]\n",
      " [0.11377246]\n",
      " [0.13173653]\n",
      " [0.11976048]\n",
      " [0.13772455]\n",
      " [0.25748503]\n",
      " [0.11976048]\n",
      " [0.16167665]\n",
      " [0.04790419]\n",
      " [0.07185629]\n",
      " [0.26946108]\n",
      " [0.10179641]\n",
      " [0.07185629]\n",
      " [0.13772455]\n",
      " [0.08982036]\n",
      " [0.07185629]\n",
      " [0.13173653]\n",
      " [0.20958084]\n",
      " [0.03592814]\n",
      " [0.07784431]\n",
      " [0.17365269]\n",
      " [0.07784431]\n",
      " [0.10179641]\n",
      " [0.11377246]]\n"
     ]
    }
   ],
   "source": [
    "# 3. Training Data Set\n",
    "x_data = scaler_x.transform(raw_data[['Solar.R', 'Wind', 'Temp']].values)\n",
    "print(x_data)\n",
    "t_data = scaler_t.transform(raw_data[['Ozone']].values.reshape(-1, 1))\n",
    "print(t_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e5ddaaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e5b9b8b640>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이제 이 아래 부분들만 잘 설정해줘도 Model이 나온다.\n",
    "#     그런데 실패하는 이유는 대부분 데이터 핸들링이 제대로 안 됐기 때문이다.\n",
    "\n",
    "# Model\n",
    "model = Sequential()\n",
    "\n",
    "# Layer 추가\n",
    "model.add(Flatten(input_shape=(3,)))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Model 설정\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4), loss='mse')\n",
    "\n",
    "# Model 학습\n",
    "model.fit(x_data, t_data, epochs=2000, verbose=0)\n",
    "#     출력 : <keras.callbacks.History at 0x1e5b9b8b640>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "288d3cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 우리 모델이 잘 만들어졌는지, 좋은 모델인지 평가하기\n",
    "# 적당한 평가 기준이 없기 때문에 지금은 일단 넘어가자.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8fdb9854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.43730887 0.41847826 0.575     ]]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "[[0.20896652]]\n",
      "[[35.897408]]\n"
     ]
    }
   ],
   "source": [
    "# 모델이 완성됐으니, 예측 작업 시작\n",
    "# 예측하고자 하는 목표 : 태양광 150, 바람 10, 온도 80 일 경우의 오존량\n",
    "predict_data = np.array([[150.0, 10.0, 80.0]])\n",
    "scaled_predict_data = scaler_x.transform(predict_data)\n",
    "print(scaled_predict_data) # 출력 : [[0.43730887 0.41847826 0.575     ]]\n",
    "result = model.predict(scaled_predict_data)\n",
    "print(result)\n",
    "# 출력\n",
    "#     1/1 [==============================] - 0s 58ms/step\n",
    "#     [[0.20896652]]\n",
    "final_result = scaler_t.inverse_transform(result)\n",
    "# transfrom\n",
    "#     정규화. 0과 1 사이의 값으로 변환\n",
    "# inverse_transform\n",
    "#     역정규화\n",
    "print(final_result) # 출력 : [[35.897408]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ec2b97",
   "metadata": {},
   "source": [
    "## Logistic Regression 구현 예제\n",
    "### Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "617042ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression 구현하기\n",
    "# Binary Classification(이항분류)\n",
    "\n",
    "# admission.zip\n",
    "\n",
    "# 필요한 모듈 불러오기\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler # 정규화\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#     옵티마이저 뭐 쓸 지 잘 모르겠으면 그냥 Adam 쓰면 된다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bbdb431d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  gre   gpa  rank\n",
       "0      0  380  3.61     3\n",
       "1      1  660  3.67     3\n",
       "2      1  800  4.00     1\n",
       "3      1  640  3.19     4\n",
       "4      0  520  2.93     4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(400, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   admit   400 non-null    int64  \n",
      " 1   gre     400 non-null    int64  \n",
      " 2   gpa     400 non-null    float64\n",
      " 3   rank    400 non-null    int64  \n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 12.6 KB\n",
      "None\n",
      "(382, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Raw Data Loading + Data Preprocessing\n",
    "\n",
    "# 데이터 전처리 중 반드시 해야할 3가지\n",
    "# 1. 결측치\n",
    "# 2. 이상치\n",
    "# 3. 정규화\n",
    "\n",
    "df = pd.read_csv('./data/admission.csv')\n",
    "display(df.head(), df.shape) # 출력 : (400, 4)\n",
    "#     admit : 합격여부 (종속변수)\n",
    "#     gre, gpa : 시험 과목 성적\n",
    "#     rank : 등급(사용 안 할 예정)\n",
    "\n",
    "# 1. 결측치 처리\n",
    "print(df.info()) # data frame에 대한 정보 출력\n",
    "# Non-Null Count\n",
    "#     non-null인 데이터의 개수\n",
    "#     모두 400개로 나오기 때문에, 결측치 없음을 확인\n",
    "\n",
    "# 2. 이상치 처리\n",
    "# 이상치 처리 방법\n",
    "# 가장 대표적인 방법 2가지\n",
    "#     1. Tukey Fence\n",
    "#         4분위를 이용하는 방법\n",
    "#     2. Z-Score 방식\n",
    "#         정규분포를 이용하는 방법\n",
    "# 우리는 2번 Z-Score 방식을 활용해보자.\n",
    "#     코드는 교수님께서 제공해주심\n",
    "\n",
    "# Z-Score 방식으로 이상치 처리하기\n",
    "from scipy import stats\n",
    "zscore_threshold = 2.0 # zscore outliers 임계값 (2.0이하가 optimal)\n",
    "for col in df.columns:\n",
    "    outliers = df[col][(np.abs(stats.zscore(df[col])) > zscore_threshold)]\n",
    "    df = df.loc[~df[col].isin(outliers)]\n",
    "print(df.shape)  # (382, 4)\n",
    "#     18개의 이상치를 발견해서 제거한 것\n",
    "\n",
    "# 3. 정규화 작업\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df[['gre', 'gpa']].values) # fancy indexing 써서 두 열 뽑아오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3925956c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data Set\n",
    "x_data = scaler.transform(df[['gre', 'gpa']].values)\n",
    "# print(x_data)\n",
    "# 출력\n",
    "#     앞열은 gre점수, 뒷열은 gpa점수\n",
    "t_data = df['admit'].values.reshape(-1, 1)\n",
    "# 정규화가 필요없다. 그냥 가져오면 됨\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "75b53d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e5c2a95580>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model\n",
    "model = Sequential()\n",
    "\n",
    "# Model에 Layer 추가\n",
    "# 독립변수의 개수만큼 input layer의 동그라미가 있어야 한다.\n",
    "# 지금 독립변수 2개니까 동그라미 2개 사용\n",
    "model.add(Flatten(input_shape=(2,)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# linear\n",
    "#     예전에는 결과값을 그대로 내보냈다.\n",
    "# sigmoid\n",
    "#     이제는 결과값을 sigmoid라는 함수에 넣어서 내보낸다.\n",
    "\n",
    "# Model 설정\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy')\n",
    "# loss\n",
    "#     binary_crossentropy\n",
    "#     loss 계산식의 종류.\n",
    "\n",
    "# Model 학습\n",
    "model.fit(x_data, t_data, epochs=2000, verbose=0)\n",
    "# 출력\n",
    "#     <keras.callbacks.History at 0x1e5bb10bcd0>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9145de",
   "metadata": {},
   "source": [
    "## 만들어진 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ffd4a2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step\n",
      "[[0.30640313]]\n"
     ]
    }
   ],
   "source": [
    "# 예측하기\n",
    "# 성적이 550, 3.5 일 때의 합격여부 알아보기\n",
    "\n",
    "# 정규화\n",
    "predict_data = np.array([[550.0, 3.5]])\n",
    "scaled_predict_data = scaler.transform(predict_data)\n",
    "result = model.predict(scaled_predict_data)\n",
    "print(result)\n",
    "# 출력\n",
    "#     [[0.30640313]]\n",
    "#     합격할 확률이 0.3 정도 된다고 판단할 수 있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985ba2f5",
   "metadata": {},
   "source": [
    "## Metric 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "57cbcd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data Set\n",
    "x_data = scaler.transform(df[['gre', 'gpa']].values)\n",
    "t_data = df['admit'].values.reshape(-1, 1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_data_train, x_data_test, t_data_train, t_data_test = \\\n",
    "    train_test_split(x_data, t_data, test_size=0.2)\n",
    "# 역슬래시 '\\' 는 코드가 아랫줄에 이어져있다는 의미\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fe730bca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.6693 - accuracy: 0.6516 - val_loss: 0.6585 - val_accuracy: 0.6721\n",
      "Epoch 2/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6690 - accuracy: 0.6557 - val_loss: 0.6583 - val_accuracy: 0.6721\n",
      "Epoch 3/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6689 - accuracy: 0.6516 - val_loss: 0.6582 - val_accuracy: 0.6721\n",
      "Epoch 4/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6687 - accuracy: 0.6516 - val_loss: 0.6580 - val_accuracy: 0.6721\n",
      "Epoch 5/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6686 - accuracy: 0.6516 - val_loss: 0.6578 - val_accuracy: 0.6721\n",
      "Epoch 6/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6684 - accuracy: 0.6516 - val_loss: 0.6577 - val_accuracy: 0.6721\n",
      "Epoch 7/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6683 - accuracy: 0.6557 - val_loss: 0.6576 - val_accuracy: 0.6721\n",
      "Epoch 8/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6681 - accuracy: 0.6557 - val_loss: 0.6574 - val_accuracy: 0.6721\n",
      "Epoch 9/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6680 - accuracy: 0.6557 - val_loss: 0.6572 - val_accuracy: 0.6721\n",
      "Epoch 10/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6678 - accuracy: 0.6557 - val_loss: 0.6571 - val_accuracy: 0.6721\n",
      "Epoch 11/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6677 - accuracy: 0.6557 - val_loss: 0.6569 - val_accuracy: 0.6721\n",
      "Epoch 12/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6676 - accuracy: 0.6557 - val_loss: 0.6568 - val_accuracy: 0.6721\n",
      "Epoch 13/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6673 - accuracy: 0.6557 - val_loss: 0.6566 - val_accuracy: 0.6721\n",
      "Epoch 14/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6673 - accuracy: 0.6557 - val_loss: 0.6565 - val_accuracy: 0.6885\n",
      "Epoch 15/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6671 - accuracy: 0.6557 - val_loss: 0.6563 - val_accuracy: 0.6885\n",
      "Epoch 16/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6669 - accuracy: 0.6557 - val_loss: 0.6562 - val_accuracy: 0.6721\n",
      "Epoch 17/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6668 - accuracy: 0.6557 - val_loss: 0.6560 - val_accuracy: 0.6721\n",
      "Epoch 18/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6666 - accuracy: 0.6516 - val_loss: 0.6559 - val_accuracy: 0.6721\n",
      "Epoch 19/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6665 - accuracy: 0.6516 - val_loss: 0.6557 - val_accuracy: 0.6721\n",
      "Epoch 20/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6664 - accuracy: 0.6516 - val_loss: 0.6556 - val_accuracy: 0.6721\n",
      "Epoch 21/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6662 - accuracy: 0.6516 - val_loss: 0.6554 - val_accuracy: 0.6721\n",
      "Epoch 22/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6660 - accuracy: 0.6516 - val_loss: 0.6553 - val_accuracy: 0.6721\n",
      "Epoch 23/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6659 - accuracy: 0.6516 - val_loss: 0.6551 - val_accuracy: 0.6721\n",
      "Epoch 24/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6658 - accuracy: 0.6475 - val_loss: 0.6550 - val_accuracy: 0.6721\n",
      "Epoch 25/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6656 - accuracy: 0.6516 - val_loss: 0.6548 - val_accuracy: 0.6721\n",
      "Epoch 26/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6655 - accuracy: 0.6516 - val_loss: 0.6547 - val_accuracy: 0.6721\n",
      "Epoch 27/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6653 - accuracy: 0.6516 - val_loss: 0.6545 - val_accuracy: 0.6721\n",
      "Epoch 28/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6652 - accuracy: 0.6516 - val_loss: 0.6544 - val_accuracy: 0.6721\n",
      "Epoch 29/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6651 - accuracy: 0.6516 - val_loss: 0.6542 - val_accuracy: 0.6721\n",
      "Epoch 30/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6649 - accuracy: 0.6516 - val_loss: 0.6541 - val_accuracy: 0.6885\n",
      "Epoch 31/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6648 - accuracy: 0.6557 - val_loss: 0.6539 - val_accuracy: 0.6885\n",
      "Epoch 32/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6646 - accuracy: 0.6557 - val_loss: 0.6538 - val_accuracy: 0.6885\n",
      "Epoch 33/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6645 - accuracy: 0.6557 - val_loss: 0.6536 - val_accuracy: 0.6885\n",
      "Epoch 34/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6643 - accuracy: 0.6557 - val_loss: 0.6535 - val_accuracy: 0.6885\n",
      "Epoch 35/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6642 - accuracy: 0.6557 - val_loss: 0.6533 - val_accuracy: 0.6885\n",
      "Epoch 36/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6641 - accuracy: 0.6557 - val_loss: 0.6532 - val_accuracy: 0.6885\n",
      "Epoch 37/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6639 - accuracy: 0.6557 - val_loss: 0.6530 - val_accuracy: 0.6885\n",
      "Epoch 38/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6638 - accuracy: 0.6516 - val_loss: 0.6529 - val_accuracy: 0.6885\n",
      "Epoch 39/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6636 - accuracy: 0.6516 - val_loss: 0.6528 - val_accuracy: 0.6885\n",
      "Epoch 40/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6635 - accuracy: 0.6516 - val_loss: 0.6526 - val_accuracy: 0.6885\n",
      "Epoch 41/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6634 - accuracy: 0.6516 - val_loss: 0.6525 - val_accuracy: 0.6885\n",
      "Epoch 42/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6632 - accuracy: 0.6516 - val_loss: 0.6524 - val_accuracy: 0.6885\n",
      "Epoch 43/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6631 - accuracy: 0.6516 - val_loss: 0.6522 - val_accuracy: 0.6885\n",
      "Epoch 44/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6630 - accuracy: 0.6557 - val_loss: 0.6521 - val_accuracy: 0.6885\n",
      "Epoch 45/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6628 - accuracy: 0.6557 - val_loss: 0.6519 - val_accuracy: 0.6885\n",
      "Epoch 46/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6627 - accuracy: 0.6557 - val_loss: 0.6518 - val_accuracy: 0.6885\n",
      "Epoch 47/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6626 - accuracy: 0.6598 - val_loss: 0.6516 - val_accuracy: 0.6885\n",
      "Epoch 48/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6624 - accuracy: 0.6598 - val_loss: 0.6515 - val_accuracy: 0.6885\n",
      "Epoch 49/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6623 - accuracy: 0.6598 - val_loss: 0.6514 - val_accuracy: 0.6885\n",
      "Epoch 50/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6621 - accuracy: 0.6598 - val_loss: 0.6512 - val_accuracy: 0.6885\n",
      "Epoch 51/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6620 - accuracy: 0.6598 - val_loss: 0.6511 - val_accuracy: 0.6885\n",
      "Epoch 52/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6619 - accuracy: 0.6598 - val_loss: 0.6509 - val_accuracy: 0.6885\n",
      "Epoch 53/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6617 - accuracy: 0.6598 - val_loss: 0.6508 - val_accuracy: 0.6885\n",
      "Epoch 54/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6616 - accuracy: 0.6639 - val_loss: 0.6507 - val_accuracy: 0.6885\n",
      "Epoch 55/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6615 - accuracy: 0.6639 - val_loss: 0.6505 - val_accuracy: 0.6885\n",
      "Epoch 56/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6613 - accuracy: 0.6639 - val_loss: 0.6504 - val_accuracy: 0.6885\n",
      "Epoch 57/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6612 - accuracy: 0.6639 - val_loss: 0.6502 - val_accuracy: 0.6885\n",
      "Epoch 58/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6611 - accuracy: 0.6639 - val_loss: 0.6501 - val_accuracy: 0.6885\n",
      "Epoch 59/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6610 - accuracy: 0.6680 - val_loss: 0.6500 - val_accuracy: 0.6885\n",
      "Epoch 60/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6608 - accuracy: 0.6680 - val_loss: 0.6498 - val_accuracy: 0.6885\n",
      "Epoch 61/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6607 - accuracy: 0.6721 - val_loss: 0.6497 - val_accuracy: 0.6885\n",
      "Epoch 62/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6605 - accuracy: 0.6721 - val_loss: 0.6495 - val_accuracy: 0.6885\n",
      "Epoch 63/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6604 - accuracy: 0.6721 - val_loss: 0.6494 - val_accuracy: 0.6885\n",
      "Epoch 64/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6603 - accuracy: 0.6721 - val_loss: 0.6493 - val_accuracy: 0.6885\n",
      "Epoch 65/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6602 - accuracy: 0.6721 - val_loss: 0.6492 - val_accuracy: 0.6885\n",
      "Epoch 66/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6600 - accuracy: 0.6721 - val_loss: 0.6490 - val_accuracy: 0.6885\n",
      "Epoch 67/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6599 - accuracy: 0.6721 - val_loss: 0.6489 - val_accuracy: 0.6885\n",
      "Epoch 68/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6598 - accuracy: 0.6721 - val_loss: 0.6487 - val_accuracy: 0.6885\n",
      "Epoch 69/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6597 - accuracy: 0.6721 - val_loss: 0.6486 - val_accuracy: 0.6885\n",
      "Epoch 70/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6595 - accuracy: 0.6721 - val_loss: 0.6485 - val_accuracy: 0.6885\n",
      "Epoch 71/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6594 - accuracy: 0.6721 - val_loss: 0.6484 - val_accuracy: 0.6885\n",
      "Epoch 72/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6593 - accuracy: 0.6721 - val_loss: 0.6482 - val_accuracy: 0.6885\n",
      "Epoch 73/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6591 - accuracy: 0.6721 - val_loss: 0.6481 - val_accuracy: 0.6885\n",
      "Epoch 74/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6590 - accuracy: 0.6721 - val_loss: 0.6480 - val_accuracy: 0.6885\n",
      "Epoch 75/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6589 - accuracy: 0.6721 - val_loss: 0.6478 - val_accuracy: 0.6885\n",
      "Epoch 76/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6588 - accuracy: 0.6721 - val_loss: 0.6477 - val_accuracy: 0.6885\n",
      "Epoch 77/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6587 - accuracy: 0.6721 - val_loss: 0.6476 - val_accuracy: 0.6885\n",
      "Epoch 78/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6585 - accuracy: 0.6721 - val_loss: 0.6475 - val_accuracy: 0.6885\n",
      "Epoch 79/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6584 - accuracy: 0.6721 - val_loss: 0.6473 - val_accuracy: 0.6885\n",
      "Epoch 80/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6583 - accuracy: 0.6721 - val_loss: 0.6472 - val_accuracy: 0.6885\n",
      "Epoch 81/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6581 - accuracy: 0.6721 - val_loss: 0.6471 - val_accuracy: 0.6885\n",
      "Epoch 82/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6581 - accuracy: 0.6721 - val_loss: 0.6469 - val_accuracy: 0.6885\n",
      "Epoch 83/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6579 - accuracy: 0.6721 - val_loss: 0.6468 - val_accuracy: 0.6885\n",
      "Epoch 84/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6578 - accuracy: 0.6721 - val_loss: 0.6467 - val_accuracy: 0.6885\n",
      "Epoch 85/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6577 - accuracy: 0.6721 - val_loss: 0.6465 - val_accuracy: 0.6885\n",
      "Epoch 86/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6575 - accuracy: 0.6721 - val_loss: 0.6464 - val_accuracy: 0.6885\n",
      "Epoch 87/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6574 - accuracy: 0.6680 - val_loss: 0.6463 - val_accuracy: 0.6885\n",
      "Epoch 88/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6573 - accuracy: 0.6680 - val_loss: 0.6462 - val_accuracy: 0.6885\n",
      "Epoch 89/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6571 - accuracy: 0.6680 - val_loss: 0.6460 - val_accuracy: 0.6885\n",
      "Epoch 90/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6570 - accuracy: 0.6680 - val_loss: 0.6459 - val_accuracy: 0.6885\n",
      "Epoch 91/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6569 - accuracy: 0.6680 - val_loss: 0.6458 - val_accuracy: 0.6885\n",
      "Epoch 92/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6568 - accuracy: 0.6680 - val_loss: 0.6457 - val_accuracy: 0.6885\n",
      "Epoch 93/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6567 - accuracy: 0.6680 - val_loss: 0.6455 - val_accuracy: 0.6885\n",
      "Epoch 94/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6566 - accuracy: 0.6680 - val_loss: 0.6454 - val_accuracy: 0.6885\n",
      "Epoch 95/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6565 - accuracy: 0.6680 - val_loss: 0.6453 - val_accuracy: 0.6885\n",
      "Epoch 96/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6563 - accuracy: 0.6680 - val_loss: 0.6452 - val_accuracy: 0.6885\n",
      "Epoch 97/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6562 - accuracy: 0.6680 - val_loss: 0.6450 - val_accuracy: 0.6885\n",
      "Epoch 98/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6561 - accuracy: 0.6680 - val_loss: 0.6449 - val_accuracy: 0.6885\n",
      "Epoch 99/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6560 - accuracy: 0.6680 - val_loss: 0.6448 - val_accuracy: 0.6885\n",
      "Epoch 100/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6559 - accuracy: 0.6680 - val_loss: 0.6447 - val_accuracy: 0.6885\n",
      "Epoch 101/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6558 - accuracy: 0.6680 - val_loss: 0.6446 - val_accuracy: 0.6885\n",
      "Epoch 102/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6556 - accuracy: 0.6680 - val_loss: 0.6444 - val_accuracy: 0.6885\n",
      "Epoch 103/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6556 - accuracy: 0.6680 - val_loss: 0.6443 - val_accuracy: 0.6885\n",
      "Epoch 104/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6554 - accuracy: 0.6680 - val_loss: 0.6442 - val_accuracy: 0.6885\n",
      "Epoch 105/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6553 - accuracy: 0.6680 - val_loss: 0.6441 - val_accuracy: 0.6885\n",
      "Epoch 106/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6552 - accuracy: 0.6680 - val_loss: 0.6440 - val_accuracy: 0.6885\n",
      "Epoch 107/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6551 - accuracy: 0.6680 - val_loss: 0.6439 - val_accuracy: 0.6885\n",
      "Epoch 108/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6549 - accuracy: 0.6680 - val_loss: 0.6437 - val_accuracy: 0.6885\n",
      "Epoch 109/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6548 - accuracy: 0.6680 - val_loss: 0.6436 - val_accuracy: 0.6885\n",
      "Epoch 110/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6547 - accuracy: 0.6680 - val_loss: 0.6435 - val_accuracy: 0.6885\n",
      "Epoch 111/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6546 - accuracy: 0.6680 - val_loss: 0.6434 - val_accuracy: 0.6885\n",
      "Epoch 112/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6545 - accuracy: 0.6680 - val_loss: 0.6433 - val_accuracy: 0.6885\n",
      "Epoch 113/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6544 - accuracy: 0.6680 - val_loss: 0.6431 - val_accuracy: 0.6885\n",
      "Epoch 114/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6543 - accuracy: 0.6680 - val_loss: 0.6430 - val_accuracy: 0.6885\n",
      "Epoch 115/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6541 - accuracy: 0.6680 - val_loss: 0.6429 - val_accuracy: 0.6885\n",
      "Epoch 116/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6540 - accuracy: 0.6680 - val_loss: 0.6428 - val_accuracy: 0.6885\n",
      "Epoch 117/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6539 - accuracy: 0.6680 - val_loss: 0.6427 - val_accuracy: 0.6885\n",
      "Epoch 118/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6538 - accuracy: 0.6680 - val_loss: 0.6426 - val_accuracy: 0.6885\n",
      "Epoch 119/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6537 - accuracy: 0.6680 - val_loss: 0.6424 - val_accuracy: 0.6885\n",
      "Epoch 120/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6536 - accuracy: 0.6680 - val_loss: 0.6423 - val_accuracy: 0.6885\n",
      "Epoch 121/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6535 - accuracy: 0.6680 - val_loss: 0.6422 - val_accuracy: 0.6885\n",
      "Epoch 122/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6533 - accuracy: 0.6680 - val_loss: 0.6421 - val_accuracy: 0.6885\n",
      "Epoch 123/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6532 - accuracy: 0.6680 - val_loss: 0.6420 - val_accuracy: 0.6885\n",
      "Epoch 124/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6531 - accuracy: 0.6680 - val_loss: 0.6419 - val_accuracy: 0.6885\n",
      "Epoch 125/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6530 - accuracy: 0.6680 - val_loss: 0.6418 - val_accuracy: 0.6885\n",
      "Epoch 126/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6529 - accuracy: 0.6680 - val_loss: 0.6416 - val_accuracy: 0.6885\n",
      "Epoch 127/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6528 - accuracy: 0.6680 - val_loss: 0.6415 - val_accuracy: 0.6885\n",
      "Epoch 128/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6527 - accuracy: 0.6680 - val_loss: 0.6414 - val_accuracy: 0.6885\n",
      "Epoch 129/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6526 - accuracy: 0.6680 - val_loss: 0.6413 - val_accuracy: 0.6885\n",
      "Epoch 130/500\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6525 - accuracy: 0.6680 - val_loss: 0.6412 - val_accuracy: 0.6885\n",
      "Epoch 131/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6524 - accuracy: 0.6680 - val_loss: 0.6411 - val_accuracy: 0.6885\n",
      "Epoch 132/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6522 - accuracy: 0.6680 - val_loss: 0.6409 - val_accuracy: 0.6885\n",
      "Epoch 133/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6521 - accuracy: 0.6680 - val_loss: 0.6408 - val_accuracy: 0.6885\n",
      "Epoch 134/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6520 - accuracy: 0.6680 - val_loss: 0.6407 - val_accuracy: 0.6885\n",
      "Epoch 135/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6519 - accuracy: 0.6680 - val_loss: 0.6406 - val_accuracy: 0.6885\n",
      "Epoch 136/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6518 - accuracy: 0.6680 - val_loss: 0.6405 - val_accuracy: 0.6885\n",
      "Epoch 137/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6517 - accuracy: 0.6680 - val_loss: 0.6404 - val_accuracy: 0.6885\n",
      "Epoch 138/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6516 - accuracy: 0.6680 - val_loss: 0.6403 - val_accuracy: 0.6885\n",
      "Epoch 139/500\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6515 - accuracy: 0.6680 - val_loss: 0.6402 - val_accuracy: 0.6885\n",
      "Epoch 140/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6514 - accuracy: 0.6680 - val_loss: 0.6401 - val_accuracy: 0.6885\n",
      "Epoch 141/500\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6513 - accuracy: 0.6680 - val_loss: 0.6400 - val_accuracy: 0.6885\n",
      "Epoch 142/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6512 - accuracy: 0.6680 - val_loss: 0.6398 - val_accuracy: 0.6885\n",
      "Epoch 143/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6511 - accuracy: 0.6680 - val_loss: 0.6397 - val_accuracy: 0.6885\n",
      "Epoch 144/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6510 - accuracy: 0.6680 - val_loss: 0.6396 - val_accuracy: 0.6885\n",
      "Epoch 145/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6508 - accuracy: 0.6680 - val_loss: 0.6395 - val_accuracy: 0.6885\n",
      "Epoch 146/500\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6508 - accuracy: 0.6680 - val_loss: 0.6394 - val_accuracy: 0.6885\n",
      "Epoch 147/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6507 - accuracy: 0.6680 - val_loss: 0.6393 - val_accuracy: 0.6885\n",
      "Epoch 148/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6506 - accuracy: 0.6680 - val_loss: 0.6392 - val_accuracy: 0.6885\n",
      "Epoch 149/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6504 - accuracy: 0.6721 - val_loss: 0.6391 - val_accuracy: 0.6885\n",
      "Epoch 150/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6503 - accuracy: 0.6721 - val_loss: 0.6390 - val_accuracy: 0.6885\n",
      "Epoch 151/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6502 - accuracy: 0.6721 - val_loss: 0.6389 - val_accuracy: 0.6885\n",
      "Epoch 152/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6501 - accuracy: 0.6721 - val_loss: 0.6388 - val_accuracy: 0.6885\n",
      "Epoch 153/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6500 - accuracy: 0.6721 - val_loss: 0.6387 - val_accuracy: 0.6885\n",
      "Epoch 154/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6499 - accuracy: 0.6721 - val_loss: 0.6386 - val_accuracy: 0.6885\n",
      "Epoch 155/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6498 - accuracy: 0.6721 - val_loss: 0.6385 - val_accuracy: 0.6885\n",
      "Epoch 156/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6498 - accuracy: 0.6721 - val_loss: 0.6384 - val_accuracy: 0.6885\n",
      "Epoch 157/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6496 - accuracy: 0.6721 - val_loss: 0.6383 - val_accuracy: 0.6885\n",
      "Epoch 158/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6496 - accuracy: 0.6721 - val_loss: 0.6382 - val_accuracy: 0.6885\n",
      "Epoch 159/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6494 - accuracy: 0.6721 - val_loss: 0.6381 - val_accuracy: 0.6885\n",
      "Epoch 160/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6494 - accuracy: 0.6721 - val_loss: 0.6380 - val_accuracy: 0.6885\n",
      "Epoch 161/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6492 - accuracy: 0.6721 - val_loss: 0.6379 - val_accuracy: 0.6885\n",
      "Epoch 162/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6491 - accuracy: 0.6721 - val_loss: 0.6378 - val_accuracy: 0.6721\n",
      "Epoch 163/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6491 - accuracy: 0.6721 - val_loss: 0.6377 - val_accuracy: 0.6721\n",
      "Epoch 164/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6490 - accuracy: 0.6721 - val_loss: 0.6376 - val_accuracy: 0.6721\n",
      "Epoch 165/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6489 - accuracy: 0.6721 - val_loss: 0.6375 - val_accuracy: 0.6721\n",
      "Epoch 166/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6487 - accuracy: 0.6721 - val_loss: 0.6374 - val_accuracy: 0.6721\n",
      "Epoch 167/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6487 - accuracy: 0.6721 - val_loss: 0.6373 - val_accuracy: 0.6721\n",
      "Epoch 168/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6486 - accuracy: 0.6721 - val_loss: 0.6372 - val_accuracy: 0.6721\n",
      "Epoch 169/500\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6485 - accuracy: 0.6721 - val_loss: 0.6371 - val_accuracy: 0.6721\n",
      "Epoch 170/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6484 - accuracy: 0.6721 - val_loss: 0.6370 - val_accuracy: 0.6721\n",
      "Epoch 171/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6483 - accuracy: 0.6721 - val_loss: 0.6369 - val_accuracy: 0.6721\n",
      "Epoch 172/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6482 - accuracy: 0.6721 - val_loss: 0.6368 - val_accuracy: 0.6721\n",
      "Epoch 173/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6481 - accuracy: 0.6721 - val_loss: 0.6367 - val_accuracy: 0.6721\n",
      "Epoch 174/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6480 - accuracy: 0.6721 - val_loss: 0.6366 - val_accuracy: 0.6721\n",
      "Epoch 175/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6479 - accuracy: 0.6721 - val_loss: 0.6365 - val_accuracy: 0.6721\n",
      "Epoch 176/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6478 - accuracy: 0.6721 - val_loss: 0.6364 - val_accuracy: 0.6721\n",
      "Epoch 177/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6477 - accuracy: 0.6721 - val_loss: 0.6363 - val_accuracy: 0.6721\n",
      "Epoch 178/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6476 - accuracy: 0.6721 - val_loss: 0.6362 - val_accuracy: 0.6721\n",
      "Epoch 179/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6476 - accuracy: 0.6721 - val_loss: 0.6361 - val_accuracy: 0.6721\n",
      "Epoch 180/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6474 - accuracy: 0.6721 - val_loss: 0.6360 - val_accuracy: 0.6721\n",
      "Epoch 181/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6474 - accuracy: 0.6721 - val_loss: 0.6359 - val_accuracy: 0.6721\n",
      "Epoch 182/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6473 - accuracy: 0.6721 - val_loss: 0.6358 - val_accuracy: 0.6721\n",
      "Epoch 183/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6472 - accuracy: 0.6721 - val_loss: 0.6358 - val_accuracy: 0.6721\n",
      "Epoch 184/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6471 - accuracy: 0.6721 - val_loss: 0.6357 - val_accuracy: 0.6721\n",
      "Epoch 185/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6470 - accuracy: 0.6721 - val_loss: 0.6356 - val_accuracy: 0.6721\n",
      "Epoch 186/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6469 - accuracy: 0.6721 - val_loss: 0.6355 - val_accuracy: 0.6721\n",
      "Epoch 187/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6468 - accuracy: 0.6721 - val_loss: 0.6354 - val_accuracy: 0.6721\n",
      "Epoch 188/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6467 - accuracy: 0.6721 - val_loss: 0.6353 - val_accuracy: 0.6721\n",
      "Epoch 189/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6466 - accuracy: 0.6721 - val_loss: 0.6352 - val_accuracy: 0.6721\n",
      "Epoch 190/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6465 - accuracy: 0.6721 - val_loss: 0.6351 - val_accuracy: 0.6721\n",
      "Epoch 191/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6465 - accuracy: 0.6721 - val_loss: 0.6350 - val_accuracy: 0.6721\n",
      "Epoch 192/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6463 - accuracy: 0.6721 - val_loss: 0.6349 - val_accuracy: 0.6721\n",
      "Epoch 193/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6463 - accuracy: 0.6721 - val_loss: 0.6349 - val_accuracy: 0.6721\n",
      "Epoch 194/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6462 - accuracy: 0.6721 - val_loss: 0.6348 - val_accuracy: 0.6721\n",
      "Epoch 195/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6461 - accuracy: 0.6721 - val_loss: 0.6347 - val_accuracy: 0.6721\n",
      "Epoch 196/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6460 - accuracy: 0.6721 - val_loss: 0.6346 - val_accuracy: 0.6721\n",
      "Epoch 197/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6459 - accuracy: 0.6721 - val_loss: 0.6345 - val_accuracy: 0.6721\n",
      "Epoch 198/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6458 - accuracy: 0.6721 - val_loss: 0.6344 - val_accuracy: 0.6721\n",
      "Epoch 199/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6457 - accuracy: 0.6721 - val_loss: 0.6343 - val_accuracy: 0.6721\n",
      "Epoch 200/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6456 - accuracy: 0.6721 - val_loss: 0.6342 - val_accuracy: 0.6721\n",
      "Epoch 201/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6455 - accuracy: 0.6721 - val_loss: 0.6341 - val_accuracy: 0.6721\n",
      "Epoch 202/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6455 - accuracy: 0.6721 - val_loss: 0.6340 - val_accuracy: 0.6721\n",
      "Epoch 203/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6454 - accuracy: 0.6721 - val_loss: 0.6339 - val_accuracy: 0.6721\n",
      "Epoch 204/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6453 - accuracy: 0.6721 - val_loss: 0.6339 - val_accuracy: 0.6721\n",
      "Epoch 205/500\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6452 - accuracy: 0.6721 - val_loss: 0.6338 - val_accuracy: 0.6721\n",
      "Epoch 206/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6451 - accuracy: 0.6721 - val_loss: 0.6337 - val_accuracy: 0.6721\n",
      "Epoch 207/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6450 - accuracy: 0.6721 - val_loss: 0.6336 - val_accuracy: 0.6721\n",
      "Epoch 208/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6449 - accuracy: 0.6721 - val_loss: 0.6335 - val_accuracy: 0.6721\n",
      "Epoch 209/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6449 - accuracy: 0.6721 - val_loss: 0.6334 - val_accuracy: 0.6721\n",
      "Epoch 210/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6447 - accuracy: 0.6721 - val_loss: 0.6333 - val_accuracy: 0.6721\n",
      "Epoch 211/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6447 - accuracy: 0.6721 - val_loss: 0.6332 - val_accuracy: 0.6721\n",
      "Epoch 212/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6446 - accuracy: 0.6721 - val_loss: 0.6332 - val_accuracy: 0.6721\n",
      "Epoch 213/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6445 - accuracy: 0.6721 - val_loss: 0.6331 - val_accuracy: 0.6721\n",
      "Epoch 214/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6444 - accuracy: 0.6721 - val_loss: 0.6330 - val_accuracy: 0.6721\n",
      "Epoch 215/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6443 - accuracy: 0.6721 - val_loss: 0.6329 - val_accuracy: 0.6721\n",
      "Epoch 216/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6442 - accuracy: 0.6721 - val_loss: 0.6328 - val_accuracy: 0.6721\n",
      "Epoch 217/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6441 - accuracy: 0.6721 - val_loss: 0.6327 - val_accuracy: 0.6721\n",
      "Epoch 218/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6441 - accuracy: 0.6721 - val_loss: 0.6326 - val_accuracy: 0.6721\n",
      "Epoch 219/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6440 - accuracy: 0.6721 - val_loss: 0.6326 - val_accuracy: 0.6721\n",
      "Epoch 220/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6439 - accuracy: 0.6721 - val_loss: 0.6325 - val_accuracy: 0.6721\n",
      "Epoch 221/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6438 - accuracy: 0.6721 - val_loss: 0.6324 - val_accuracy: 0.6721\n",
      "Epoch 222/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6437 - accuracy: 0.6721 - val_loss: 0.6323 - val_accuracy: 0.6721\n",
      "Epoch 223/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6436 - accuracy: 0.6721 - val_loss: 0.6322 - val_accuracy: 0.6721\n",
      "Epoch 224/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6436 - accuracy: 0.6721 - val_loss: 0.6321 - val_accuracy: 0.6721\n",
      "Epoch 225/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6434 - accuracy: 0.6721 - val_loss: 0.6321 - val_accuracy: 0.6721\n",
      "Epoch 226/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6434 - accuracy: 0.6721 - val_loss: 0.6320 - val_accuracy: 0.6721\n",
      "Epoch 227/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6433 - accuracy: 0.6721 - val_loss: 0.6319 - val_accuracy: 0.6721\n",
      "Epoch 228/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6432 - accuracy: 0.6721 - val_loss: 0.6318 - val_accuracy: 0.6721\n",
      "Epoch 229/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6431 - accuracy: 0.6721 - val_loss: 0.6317 - val_accuracy: 0.6721\n",
      "Epoch 230/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6430 - accuracy: 0.6721 - val_loss: 0.6317 - val_accuracy: 0.6721\n",
      "Epoch 231/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6430 - accuracy: 0.6721 - val_loss: 0.6316 - val_accuracy: 0.6721\n",
      "Epoch 232/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6429 - accuracy: 0.6721 - val_loss: 0.6315 - val_accuracy: 0.6721\n",
      "Epoch 233/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6428 - accuracy: 0.6721 - val_loss: 0.6314 - val_accuracy: 0.6721\n",
      "Epoch 234/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6427 - accuracy: 0.6721 - val_loss: 0.6313 - val_accuracy: 0.6721\n",
      "Epoch 235/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6426 - accuracy: 0.6721 - val_loss: 0.6312 - val_accuracy: 0.6721\n",
      "Epoch 236/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6426 - accuracy: 0.6721 - val_loss: 0.6312 - val_accuracy: 0.6721\n",
      "Epoch 237/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6425 - accuracy: 0.6721 - val_loss: 0.6311 - val_accuracy: 0.6721\n",
      "Epoch 238/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6424 - accuracy: 0.6721 - val_loss: 0.6310 - val_accuracy: 0.6721\n",
      "Epoch 239/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6423 - accuracy: 0.6721 - val_loss: 0.6309 - val_accuracy: 0.6721\n",
      "Epoch 240/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6423 - accuracy: 0.6721 - val_loss: 0.6308 - val_accuracy: 0.6721\n",
      "Epoch 241/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6422 - accuracy: 0.6721 - val_loss: 0.6308 - val_accuracy: 0.6721\n",
      "Epoch 242/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6421 - accuracy: 0.6721 - val_loss: 0.6307 - val_accuracy: 0.6721\n",
      "Epoch 243/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6420 - accuracy: 0.6721 - val_loss: 0.6306 - val_accuracy: 0.6721\n",
      "Epoch 244/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6419 - accuracy: 0.6721 - val_loss: 0.6305 - val_accuracy: 0.6721\n",
      "Epoch 245/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6418 - accuracy: 0.6721 - val_loss: 0.6305 - val_accuracy: 0.6721\n",
      "Epoch 246/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6418 - accuracy: 0.6721 - val_loss: 0.6304 - val_accuracy: 0.6721\n",
      "Epoch 247/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6417 - accuracy: 0.6721 - val_loss: 0.6303 - val_accuracy: 0.6721\n",
      "Epoch 248/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6416 - accuracy: 0.6721 - val_loss: 0.6302 - val_accuracy: 0.6721\n",
      "Epoch 249/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6415 - accuracy: 0.6721 - val_loss: 0.6301 - val_accuracy: 0.6721\n",
      "Epoch 250/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6415 - accuracy: 0.6721 - val_loss: 0.6301 - val_accuracy: 0.6721\n",
      "Epoch 251/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6414 - accuracy: 0.6721 - val_loss: 0.6300 - val_accuracy: 0.6721\n",
      "Epoch 252/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6413 - accuracy: 0.6721 - val_loss: 0.6299 - val_accuracy: 0.6721\n",
      "Epoch 253/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6412 - accuracy: 0.6721 - val_loss: 0.6298 - val_accuracy: 0.6721\n",
      "Epoch 254/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6411 - accuracy: 0.6721 - val_loss: 0.6297 - val_accuracy: 0.6721\n",
      "Epoch 255/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6410 - accuracy: 0.6721 - val_loss: 0.6297 - val_accuracy: 0.6721\n",
      "Epoch 256/500\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6410 - accuracy: 0.6721 - val_loss: 0.6296 - val_accuracy: 0.6721\n",
      "Epoch 257/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6409 - accuracy: 0.6721 - val_loss: 0.6295 - val_accuracy: 0.6721\n",
      "Epoch 258/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6408 - accuracy: 0.6721 - val_loss: 0.6294 - val_accuracy: 0.6721\n",
      "Epoch 259/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6407 - accuracy: 0.6721 - val_loss: 0.6294 - val_accuracy: 0.6721\n",
      "Epoch 260/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6407 - accuracy: 0.6721 - val_loss: 0.6293 - val_accuracy: 0.6721\n",
      "Epoch 261/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6406 - accuracy: 0.6721 - val_loss: 0.6292 - val_accuracy: 0.6721\n",
      "Epoch 262/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6405 - accuracy: 0.6721 - val_loss: 0.6291 - val_accuracy: 0.6721\n",
      "Epoch 263/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6404 - accuracy: 0.6721 - val_loss: 0.6291 - val_accuracy: 0.6721\n",
      "Epoch 264/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6404 - accuracy: 0.6721 - val_loss: 0.6290 - val_accuracy: 0.6721\n",
      "Epoch 265/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6403 - accuracy: 0.6721 - val_loss: 0.6289 - val_accuracy: 0.6721\n",
      "Epoch 266/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6402 - accuracy: 0.6721 - val_loss: 0.6288 - val_accuracy: 0.6721\n",
      "Epoch 267/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6401 - accuracy: 0.6721 - val_loss: 0.6287 - val_accuracy: 0.6721\n",
      "Epoch 268/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6401 - accuracy: 0.6721 - val_loss: 0.6287 - val_accuracy: 0.6721\n",
      "Epoch 269/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6401 - accuracy: 0.6721 - val_loss: 0.6286 - val_accuracy: 0.6721\n",
      "Epoch 270/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6399 - accuracy: 0.6721 - val_loss: 0.6285 - val_accuracy: 0.6721\n",
      "Epoch 271/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6398 - accuracy: 0.6721 - val_loss: 0.6285 - val_accuracy: 0.6721\n",
      "Epoch 272/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6398 - accuracy: 0.6721 - val_loss: 0.6284 - val_accuracy: 0.6721\n",
      "Epoch 273/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6397 - accuracy: 0.6721 - val_loss: 0.6283 - val_accuracy: 0.6721\n",
      "Epoch 274/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6396 - accuracy: 0.6721 - val_loss: 0.6282 - val_accuracy: 0.6721\n",
      "Epoch 275/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6396 - accuracy: 0.6721 - val_loss: 0.6282 - val_accuracy: 0.6721\n",
      "Epoch 276/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6395 - accuracy: 0.6721 - val_loss: 0.6281 - val_accuracy: 0.6721\n",
      "Epoch 277/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6394 - accuracy: 0.6721 - val_loss: 0.6280 - val_accuracy: 0.6721\n",
      "Epoch 278/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6393 - accuracy: 0.6721 - val_loss: 0.6279 - val_accuracy: 0.6721\n",
      "Epoch 279/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6392 - accuracy: 0.6721 - val_loss: 0.6279 - val_accuracy: 0.6721\n",
      "Epoch 280/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6391 - accuracy: 0.6721 - val_loss: 0.6278 - val_accuracy: 0.6721\n",
      "Epoch 281/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6391 - accuracy: 0.6721 - val_loss: 0.6277 - val_accuracy: 0.6721\n",
      "Epoch 282/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6390 - accuracy: 0.6721 - val_loss: 0.6276 - val_accuracy: 0.6721\n",
      "Epoch 283/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6389 - accuracy: 0.6721 - val_loss: 0.6276 - val_accuracy: 0.6721\n",
      "Epoch 284/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6388 - accuracy: 0.6721 - val_loss: 0.6275 - val_accuracy: 0.6721\n",
      "Epoch 285/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6388 - accuracy: 0.6721 - val_loss: 0.6274 - val_accuracy: 0.6721\n",
      "Epoch 286/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6387 - accuracy: 0.6721 - val_loss: 0.6274 - val_accuracy: 0.6721\n",
      "Epoch 287/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6386 - accuracy: 0.6721 - val_loss: 0.6273 - val_accuracy: 0.6721\n",
      "Epoch 288/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6386 - accuracy: 0.6721 - val_loss: 0.6272 - val_accuracy: 0.6721\n",
      "Epoch 289/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6385 - accuracy: 0.6721 - val_loss: 0.6271 - val_accuracy: 0.6721\n",
      "Epoch 290/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6384 - accuracy: 0.6721 - val_loss: 0.6271 - val_accuracy: 0.6721\n",
      "Epoch 291/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6383 - accuracy: 0.6721 - val_loss: 0.6270 - val_accuracy: 0.6721\n",
      "Epoch 292/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6383 - accuracy: 0.6721 - val_loss: 0.6269 - val_accuracy: 0.6721\n",
      "Epoch 293/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6382 - accuracy: 0.6721 - val_loss: 0.6268 - val_accuracy: 0.6721\n",
      "Epoch 294/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6381 - accuracy: 0.6721 - val_loss: 0.6268 - val_accuracy: 0.6721\n",
      "Epoch 295/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6381 - accuracy: 0.6721 - val_loss: 0.6267 - val_accuracy: 0.6721\n",
      "Epoch 296/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6380 - accuracy: 0.6721 - val_loss: 0.6266 - val_accuracy: 0.6721\n",
      "Epoch 297/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6379 - accuracy: 0.6721 - val_loss: 0.6266 - val_accuracy: 0.6721\n",
      "Epoch 298/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6379 - accuracy: 0.6721 - val_loss: 0.6265 - val_accuracy: 0.6721\n",
      "Epoch 299/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6378 - accuracy: 0.6721 - val_loss: 0.6264 - val_accuracy: 0.6721\n",
      "Epoch 300/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6377 - accuracy: 0.6721 - val_loss: 0.6264 - val_accuracy: 0.6721\n",
      "Epoch 301/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6376 - accuracy: 0.6721 - val_loss: 0.6263 - val_accuracy: 0.6721\n",
      "Epoch 302/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6376 - accuracy: 0.6721 - val_loss: 0.6262 - val_accuracy: 0.6721\n",
      "Epoch 303/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6375 - accuracy: 0.6721 - val_loss: 0.6262 - val_accuracy: 0.6721\n",
      "Epoch 304/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6374 - accuracy: 0.6721 - val_loss: 0.6261 - val_accuracy: 0.6721\n",
      "Epoch 305/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6374 - accuracy: 0.6721 - val_loss: 0.6260 - val_accuracy: 0.6721\n",
      "Epoch 306/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6373 - accuracy: 0.6721 - val_loss: 0.6260 - val_accuracy: 0.6721\n",
      "Epoch 307/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6372 - accuracy: 0.6721 - val_loss: 0.6259 - val_accuracy: 0.6721\n",
      "Epoch 308/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6372 - accuracy: 0.6721 - val_loss: 0.6258 - val_accuracy: 0.6721\n",
      "Epoch 309/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6371 - accuracy: 0.6721 - val_loss: 0.6258 - val_accuracy: 0.6721\n",
      "Epoch 310/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6370 - accuracy: 0.6721 - val_loss: 0.6257 - val_accuracy: 0.6721\n",
      "Epoch 311/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6370 - accuracy: 0.6721 - val_loss: 0.6256 - val_accuracy: 0.6721\n",
      "Epoch 312/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6369 - accuracy: 0.6721 - val_loss: 0.6256 - val_accuracy: 0.6721\n",
      "Epoch 313/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6368 - accuracy: 0.6721 - val_loss: 0.6255 - val_accuracy: 0.6721\n",
      "Epoch 314/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6368 - accuracy: 0.6721 - val_loss: 0.6255 - val_accuracy: 0.6721\n",
      "Epoch 315/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6367 - accuracy: 0.6721 - val_loss: 0.6254 - val_accuracy: 0.6721\n",
      "Epoch 316/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6366 - accuracy: 0.6721 - val_loss: 0.6253 - val_accuracy: 0.6721\n",
      "Epoch 317/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6365 - accuracy: 0.6721 - val_loss: 0.6252 - val_accuracy: 0.6721\n",
      "Epoch 318/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6365 - accuracy: 0.6721 - val_loss: 0.6252 - val_accuracy: 0.6721\n",
      "Epoch 319/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6364 - accuracy: 0.6721 - val_loss: 0.6251 - val_accuracy: 0.6721\n",
      "Epoch 320/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6363 - accuracy: 0.6721 - val_loss: 0.6250 - val_accuracy: 0.6721\n",
      "Epoch 321/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6363 - accuracy: 0.6721 - val_loss: 0.6250 - val_accuracy: 0.6721\n",
      "Epoch 322/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6362 - accuracy: 0.6721 - val_loss: 0.6249 - val_accuracy: 0.6721\n",
      "Epoch 323/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6361 - accuracy: 0.6721 - val_loss: 0.6248 - val_accuracy: 0.6721\n",
      "Epoch 324/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6360 - accuracy: 0.6721 - val_loss: 0.6248 - val_accuracy: 0.6721\n",
      "Epoch 325/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6360 - accuracy: 0.6721 - val_loss: 0.6247 - val_accuracy: 0.6721\n",
      "Epoch 326/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6359 - accuracy: 0.6721 - val_loss: 0.6246 - val_accuracy: 0.6721\n",
      "Epoch 327/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6358 - accuracy: 0.6721 - val_loss: 0.6246 - val_accuracy: 0.6721\n",
      "Epoch 328/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6358 - accuracy: 0.6721 - val_loss: 0.6245 - val_accuracy: 0.6721\n",
      "Epoch 329/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6357 - accuracy: 0.6721 - val_loss: 0.6244 - val_accuracy: 0.6721\n",
      "Epoch 330/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6357 - accuracy: 0.6721 - val_loss: 0.6244 - val_accuracy: 0.6721\n",
      "Epoch 331/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6356 - accuracy: 0.6721 - val_loss: 0.6243 - val_accuracy: 0.6721\n",
      "Epoch 332/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6355 - accuracy: 0.6721 - val_loss: 0.6242 - val_accuracy: 0.6721\n",
      "Epoch 333/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6354 - accuracy: 0.6721 - val_loss: 0.6242 - val_accuracy: 0.6721\n",
      "Epoch 334/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6354 - accuracy: 0.6721 - val_loss: 0.6241 - val_accuracy: 0.6721\n",
      "Epoch 335/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6353 - accuracy: 0.6721 - val_loss: 0.6240 - val_accuracy: 0.6721\n",
      "Epoch 336/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6352 - accuracy: 0.6721 - val_loss: 0.6240 - val_accuracy: 0.6721\n",
      "Epoch 337/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6352 - accuracy: 0.6721 - val_loss: 0.6239 - val_accuracy: 0.6721\n",
      "Epoch 338/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6351 - accuracy: 0.6721 - val_loss: 0.6239 - val_accuracy: 0.6721\n",
      "Epoch 339/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6351 - accuracy: 0.6721 - val_loss: 0.6238 - val_accuracy: 0.6721\n",
      "Epoch 340/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6350 - accuracy: 0.6721 - val_loss: 0.6237 - val_accuracy: 0.6721\n",
      "Epoch 341/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6349 - accuracy: 0.6721 - val_loss: 0.6237 - val_accuracy: 0.6721\n",
      "Epoch 342/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6349 - accuracy: 0.6721 - val_loss: 0.6236 - val_accuracy: 0.6721\n",
      "Epoch 343/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6348 - accuracy: 0.6721 - val_loss: 0.6235 - val_accuracy: 0.6721\n",
      "Epoch 344/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6348 - accuracy: 0.6721 - val_loss: 0.6235 - val_accuracy: 0.6721\n",
      "Epoch 345/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6347 - accuracy: 0.6721 - val_loss: 0.6234 - val_accuracy: 0.6721\n",
      "Epoch 346/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6347 - accuracy: 0.6721 - val_loss: 0.6234 - val_accuracy: 0.6721\n",
      "Epoch 347/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6346 - accuracy: 0.6721 - val_loss: 0.6233 - val_accuracy: 0.6721\n",
      "Epoch 348/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6345 - accuracy: 0.6721 - val_loss: 0.6232 - val_accuracy: 0.6721\n",
      "Epoch 349/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6344 - accuracy: 0.6721 - val_loss: 0.6232 - val_accuracy: 0.6721\n",
      "Epoch 350/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6344 - accuracy: 0.6721 - val_loss: 0.6231 - val_accuracy: 0.6721\n",
      "Epoch 351/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6343 - accuracy: 0.6721 - val_loss: 0.6231 - val_accuracy: 0.6721\n",
      "Epoch 352/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6343 - accuracy: 0.6721 - val_loss: 0.6230 - val_accuracy: 0.6721\n",
      "Epoch 353/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6342 - accuracy: 0.6721 - val_loss: 0.6230 - val_accuracy: 0.6721\n",
      "Epoch 354/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6342 - accuracy: 0.6721 - val_loss: 0.6229 - val_accuracy: 0.6721\n",
      "Epoch 355/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6341 - accuracy: 0.6721 - val_loss: 0.6228 - val_accuracy: 0.6721\n",
      "Epoch 356/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6340 - accuracy: 0.6721 - val_loss: 0.6228 - val_accuracy: 0.6721\n",
      "Epoch 357/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6339 - accuracy: 0.6721 - val_loss: 0.6227 - val_accuracy: 0.6721\n",
      "Epoch 358/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6339 - accuracy: 0.6721 - val_loss: 0.6227 - val_accuracy: 0.6721\n",
      "Epoch 359/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6339 - accuracy: 0.6721 - val_loss: 0.6226 - val_accuracy: 0.6721\n",
      "Epoch 360/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6338 - accuracy: 0.6721 - val_loss: 0.6225 - val_accuracy: 0.6721\n",
      "Epoch 361/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6337 - accuracy: 0.6721 - val_loss: 0.6225 - val_accuracy: 0.6721\n",
      "Epoch 362/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6337 - accuracy: 0.6721 - val_loss: 0.6224 - val_accuracy: 0.6721\n",
      "Epoch 363/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6336 - accuracy: 0.6721 - val_loss: 0.6224 - val_accuracy: 0.6721\n",
      "Epoch 364/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6336 - accuracy: 0.6721 - val_loss: 0.6223 - val_accuracy: 0.6721\n",
      "Epoch 365/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6335 - accuracy: 0.6721 - val_loss: 0.6223 - val_accuracy: 0.6721\n",
      "Epoch 366/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6334 - accuracy: 0.6721 - val_loss: 0.6222 - val_accuracy: 0.6721\n",
      "Epoch 367/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6334 - accuracy: 0.6721 - val_loss: 0.6221 - val_accuracy: 0.6721\n",
      "Epoch 368/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6333 - accuracy: 0.6721 - val_loss: 0.6221 - val_accuracy: 0.6721\n",
      "Epoch 369/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6332 - accuracy: 0.6721 - val_loss: 0.6220 - val_accuracy: 0.6721\n",
      "Epoch 370/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6332 - accuracy: 0.6721 - val_loss: 0.6220 - val_accuracy: 0.6721\n",
      "Epoch 371/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6331 - accuracy: 0.6721 - val_loss: 0.6219 - val_accuracy: 0.6721\n",
      "Epoch 372/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6331 - accuracy: 0.6721 - val_loss: 0.6219 - val_accuracy: 0.6721\n",
      "Epoch 373/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6330 - accuracy: 0.6721 - val_loss: 0.6218 - val_accuracy: 0.6721\n",
      "Epoch 374/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6329 - accuracy: 0.6721 - val_loss: 0.6217 - val_accuracy: 0.6721\n",
      "Epoch 375/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6329 - accuracy: 0.6721 - val_loss: 0.6217 - val_accuracy: 0.6721\n",
      "Epoch 376/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6328 - accuracy: 0.6721 - val_loss: 0.6216 - val_accuracy: 0.6721\n",
      "Epoch 377/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.6721 - val_loss: 0.6216 - val_accuracy: 0.6721\n",
      "Epoch 378/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.6721 - val_loss: 0.6215 - val_accuracy: 0.6721\n",
      "Epoch 379/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6326 - accuracy: 0.6721 - val_loss: 0.6215 - val_accuracy: 0.6721\n",
      "Epoch 380/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6326 - accuracy: 0.6721 - val_loss: 0.6214 - val_accuracy: 0.6721\n",
      "Epoch 381/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6325 - accuracy: 0.6721 - val_loss: 0.6213 - val_accuracy: 0.6721\n",
      "Epoch 382/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6325 - accuracy: 0.6721 - val_loss: 0.6213 - val_accuracy: 0.6721\n",
      "Epoch 383/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6324 - accuracy: 0.6721 - val_loss: 0.6212 - val_accuracy: 0.6721\n",
      "Epoch 384/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6324 - accuracy: 0.6721 - val_loss: 0.6212 - val_accuracy: 0.6721\n",
      "Epoch 385/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.6721 - val_loss: 0.6211 - val_accuracy: 0.6721\n",
      "Epoch 386/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.6721 - val_loss: 0.6211 - val_accuracy: 0.6721\n",
      "Epoch 387/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6322 - accuracy: 0.6721 - val_loss: 0.6210 - val_accuracy: 0.6721\n",
      "Epoch 388/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6321 - accuracy: 0.6721 - val_loss: 0.6210 - val_accuracy: 0.6721\n",
      "Epoch 389/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.6721 - val_loss: 0.6209 - val_accuracy: 0.6721\n",
      "Epoch 390/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.6721 - val_loss: 0.6209 - val_accuracy: 0.6721\n",
      "Epoch 391/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.6721 - val_loss: 0.6208 - val_accuracy: 0.6721\n",
      "Epoch 392/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.6721 - val_loss: 0.6208 - val_accuracy: 0.6721\n",
      "Epoch 393/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6319 - accuracy: 0.6721 - val_loss: 0.6207 - val_accuracy: 0.6721\n",
      "Epoch 394/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6318 - accuracy: 0.6721 - val_loss: 0.6207 - val_accuracy: 0.6721\n",
      "Epoch 395/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6318 - accuracy: 0.6721 - val_loss: 0.6206 - val_accuracy: 0.6721\n",
      "Epoch 396/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6317 - accuracy: 0.6721 - val_loss: 0.6205 - val_accuracy: 0.6721\n",
      "Epoch 397/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6316 - accuracy: 0.6721 - val_loss: 0.6205 - val_accuracy: 0.6721\n",
      "Epoch 398/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6316 - accuracy: 0.6721 - val_loss: 0.6204 - val_accuracy: 0.6721\n",
      "Epoch 399/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6315 - accuracy: 0.6721 - val_loss: 0.6204 - val_accuracy: 0.6721\n",
      "Epoch 400/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6315 - accuracy: 0.6721 - val_loss: 0.6203 - val_accuracy: 0.6721\n",
      "Epoch 401/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6314 - accuracy: 0.6721 - val_loss: 0.6203 - val_accuracy: 0.6721\n",
      "Epoch 402/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6313 - accuracy: 0.6721 - val_loss: 0.6202 - val_accuracy: 0.6721\n",
      "Epoch 403/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6313 - accuracy: 0.6721 - val_loss: 0.6202 - val_accuracy: 0.6721\n",
      "Epoch 404/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6313 - accuracy: 0.6721 - val_loss: 0.6201 - val_accuracy: 0.6721\n",
      "Epoch 405/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6312 - accuracy: 0.6721 - val_loss: 0.6201 - val_accuracy: 0.6721\n",
      "Epoch 406/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6311 - accuracy: 0.6721 - val_loss: 0.6200 - val_accuracy: 0.6721\n",
      "Epoch 407/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6311 - accuracy: 0.6721 - val_loss: 0.6200 - val_accuracy: 0.6721\n",
      "Epoch 408/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6310 - accuracy: 0.6721 - val_loss: 0.6199 - val_accuracy: 0.6721\n",
      "Epoch 409/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6310 - accuracy: 0.6721 - val_loss: 0.6199 - val_accuracy: 0.6721\n",
      "Epoch 410/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6309 - accuracy: 0.6721 - val_loss: 0.6198 - val_accuracy: 0.6721\n",
      "Epoch 411/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6309 - accuracy: 0.6721 - val_loss: 0.6198 - val_accuracy: 0.6721\n",
      "Epoch 412/500\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6308 - accuracy: 0.6721 - val_loss: 0.6197 - val_accuracy: 0.6721\n",
      "Epoch 413/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6307 - accuracy: 0.6721 - val_loss: 0.6197 - val_accuracy: 0.6721\n",
      "Epoch 414/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6307 - accuracy: 0.6721 - val_loss: 0.6196 - val_accuracy: 0.6721\n",
      "Epoch 415/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6306 - accuracy: 0.6721 - val_loss: 0.6196 - val_accuracy: 0.6721\n",
      "Epoch 416/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6306 - accuracy: 0.6721 - val_loss: 0.6195 - val_accuracy: 0.6721\n",
      "Epoch 417/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6305 - accuracy: 0.6721 - val_loss: 0.6195 - val_accuracy: 0.6721\n",
      "Epoch 418/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6305 - accuracy: 0.6721 - val_loss: 0.6194 - val_accuracy: 0.6721\n",
      "Epoch 419/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6304 - accuracy: 0.6721 - val_loss: 0.6194 - val_accuracy: 0.6721\n",
      "Epoch 420/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6304 - accuracy: 0.6721 - val_loss: 0.6193 - val_accuracy: 0.6721\n",
      "Epoch 421/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6304 - accuracy: 0.6721 - val_loss: 0.6193 - val_accuracy: 0.6721\n",
      "Epoch 422/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6303 - accuracy: 0.6721 - val_loss: 0.6192 - val_accuracy: 0.6721\n",
      "Epoch 423/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6302 - accuracy: 0.6721 - val_loss: 0.6192 - val_accuracy: 0.6721\n",
      "Epoch 424/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6302 - accuracy: 0.6721 - val_loss: 0.6191 - val_accuracy: 0.6721\n",
      "Epoch 425/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6301 - accuracy: 0.6721 - val_loss: 0.6191 - val_accuracy: 0.6721\n",
      "Epoch 426/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6301 - accuracy: 0.6721 - val_loss: 0.6190 - val_accuracy: 0.6721\n",
      "Epoch 427/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6300 - accuracy: 0.6721 - val_loss: 0.6190 - val_accuracy: 0.6721\n",
      "Epoch 428/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6300 - accuracy: 0.6721 - val_loss: 0.6189 - val_accuracy: 0.6721\n",
      "Epoch 429/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6299 - accuracy: 0.6721 - val_loss: 0.6189 - val_accuracy: 0.6721\n",
      "Epoch 430/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6299 - accuracy: 0.6721 - val_loss: 0.6188 - val_accuracy: 0.6721\n",
      "Epoch 431/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6298 - accuracy: 0.6721 - val_loss: 0.6188 - val_accuracy: 0.6721\n",
      "Epoch 432/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6297 - accuracy: 0.6721 - val_loss: 0.6187 - val_accuracy: 0.6721\n",
      "Epoch 433/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6297 - accuracy: 0.6721 - val_loss: 0.6187 - val_accuracy: 0.6721\n",
      "Epoch 434/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6297 - accuracy: 0.6721 - val_loss: 0.6187 - val_accuracy: 0.6721\n",
      "Epoch 435/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6296 - accuracy: 0.6721 - val_loss: 0.6186 - val_accuracy: 0.6721\n",
      "Epoch 436/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6296 - accuracy: 0.6721 - val_loss: 0.6186 - val_accuracy: 0.6721\n",
      "Epoch 437/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6295 - accuracy: 0.6721 - val_loss: 0.6185 - val_accuracy: 0.6721\n",
      "Epoch 438/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6295 - accuracy: 0.6721 - val_loss: 0.6185 - val_accuracy: 0.6721\n",
      "Epoch 439/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6294 - accuracy: 0.6721 - val_loss: 0.6184 - val_accuracy: 0.6721\n",
      "Epoch 440/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6294 - accuracy: 0.6721 - val_loss: 0.6184 - val_accuracy: 0.6721\n",
      "Epoch 441/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6293 - accuracy: 0.6721 - val_loss: 0.6184 - val_accuracy: 0.6721\n",
      "Epoch 442/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6293 - accuracy: 0.6721 - val_loss: 0.6183 - val_accuracy: 0.6721\n",
      "Epoch 443/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6292 - accuracy: 0.6721 - val_loss: 0.6183 - val_accuracy: 0.6721\n",
      "Epoch 444/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6292 - accuracy: 0.6721 - val_loss: 0.6182 - val_accuracy: 0.6721\n",
      "Epoch 445/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6291 - accuracy: 0.6721 - val_loss: 0.6182 - val_accuracy: 0.6721\n",
      "Epoch 446/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6291 - accuracy: 0.6721 - val_loss: 0.6181 - val_accuracy: 0.6721\n",
      "Epoch 447/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6290 - accuracy: 0.6721 - val_loss: 0.6181 - val_accuracy: 0.6721\n",
      "Epoch 448/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6290 - accuracy: 0.6721 - val_loss: 0.6180 - val_accuracy: 0.6721\n",
      "Epoch 449/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6289 - accuracy: 0.6721 - val_loss: 0.6180 - val_accuracy: 0.6721\n",
      "Epoch 450/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6289 - accuracy: 0.6721 - val_loss: 0.6179 - val_accuracy: 0.6721\n",
      "Epoch 451/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6289 - accuracy: 0.6721 - val_loss: 0.6179 - val_accuracy: 0.6721\n",
      "Epoch 452/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6288 - accuracy: 0.6721 - val_loss: 0.6178 - val_accuracy: 0.6721\n",
      "Epoch 453/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6287 - accuracy: 0.6721 - val_loss: 0.6178 - val_accuracy: 0.6721\n",
      "Epoch 454/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6287 - accuracy: 0.6721 - val_loss: 0.6178 - val_accuracy: 0.6721\n",
      "Epoch 455/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6286 - accuracy: 0.6721 - val_loss: 0.6177 - val_accuracy: 0.6721\n",
      "Epoch 456/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6286 - accuracy: 0.6721 - val_loss: 0.6177 - val_accuracy: 0.6721\n",
      "Epoch 457/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6285 - accuracy: 0.6721 - val_loss: 0.6176 - val_accuracy: 0.6721\n",
      "Epoch 458/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6285 - accuracy: 0.6721 - val_loss: 0.6176 - val_accuracy: 0.6721\n",
      "Epoch 459/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6284 - accuracy: 0.6721 - val_loss: 0.6175 - val_accuracy: 0.6721\n",
      "Epoch 460/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6284 - accuracy: 0.6721 - val_loss: 0.6175 - val_accuracy: 0.6721\n",
      "Epoch 461/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6283 - accuracy: 0.6721 - val_loss: 0.6174 - val_accuracy: 0.6721\n",
      "Epoch 462/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6283 - accuracy: 0.6721 - val_loss: 0.6174 - val_accuracy: 0.6721\n",
      "Epoch 463/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6283 - accuracy: 0.6721 - val_loss: 0.6174 - val_accuracy: 0.6721\n",
      "Epoch 464/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6282 - accuracy: 0.6721 - val_loss: 0.6173 - val_accuracy: 0.6721\n",
      "Epoch 465/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6282 - accuracy: 0.6721 - val_loss: 0.6173 - val_accuracy: 0.6721\n",
      "Epoch 466/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6281 - accuracy: 0.6721 - val_loss: 0.6172 - val_accuracy: 0.6721\n",
      "Epoch 467/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6281 - accuracy: 0.6721 - val_loss: 0.6172 - val_accuracy: 0.6721\n",
      "Epoch 468/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6280 - accuracy: 0.6721 - val_loss: 0.6172 - val_accuracy: 0.6721\n",
      "Epoch 469/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6280 - accuracy: 0.6721 - val_loss: 0.6171 - val_accuracy: 0.6721\n",
      "Epoch 470/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6279 - accuracy: 0.6721 - val_loss: 0.6171 - val_accuracy: 0.6721\n",
      "Epoch 471/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6279 - accuracy: 0.6721 - val_loss: 0.6170 - val_accuracy: 0.6721\n",
      "Epoch 472/500\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6279 - accuracy: 0.6721 - val_loss: 0.6170 - val_accuracy: 0.6721\n",
      "Epoch 473/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6278 - accuracy: 0.6721 - val_loss: 0.6170 - val_accuracy: 0.6721\n",
      "Epoch 474/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6278 - accuracy: 0.6721 - val_loss: 0.6169 - val_accuracy: 0.6721\n",
      "Epoch 475/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6277 - accuracy: 0.6721 - val_loss: 0.6169 - val_accuracy: 0.6721\n",
      "Epoch 476/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6277 - accuracy: 0.6721 - val_loss: 0.6168 - val_accuracy: 0.6721\n",
      "Epoch 477/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6277 - accuracy: 0.6721 - val_loss: 0.6168 - val_accuracy: 0.6721\n",
      "Epoch 478/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6276 - accuracy: 0.6721 - val_loss: 0.6167 - val_accuracy: 0.6721\n",
      "Epoch 479/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6275 - accuracy: 0.6721 - val_loss: 0.6167 - val_accuracy: 0.6721\n",
      "Epoch 480/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6275 - accuracy: 0.6721 - val_loss: 0.6167 - val_accuracy: 0.6721\n",
      "Epoch 481/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6274 - accuracy: 0.6721 - val_loss: 0.6166 - val_accuracy: 0.6721\n",
      "Epoch 482/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6274 - accuracy: 0.6721 - val_loss: 0.6166 - val_accuracy: 0.6721\n",
      "Epoch 483/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6273 - accuracy: 0.6721 - val_loss: 0.6165 - val_accuracy: 0.6721\n",
      "Epoch 484/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6273 - accuracy: 0.6721 - val_loss: 0.6165 - val_accuracy: 0.6721\n",
      "Epoch 485/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6273 - accuracy: 0.6721 - val_loss: 0.6165 - val_accuracy: 0.6721\n",
      "Epoch 486/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6272 - accuracy: 0.6721 - val_loss: 0.6164 - val_accuracy: 0.6721\n",
      "Epoch 487/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6272 - accuracy: 0.6721 - val_loss: 0.6164 - val_accuracy: 0.6721\n",
      "Epoch 488/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6271 - accuracy: 0.6721 - val_loss: 0.6163 - val_accuracy: 0.6721\n",
      "Epoch 489/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6271 - accuracy: 0.6721 - val_loss: 0.6163 - val_accuracy: 0.6721\n",
      "Epoch 490/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6270 - accuracy: 0.6721 - val_loss: 0.6163 - val_accuracy: 0.6721\n",
      "Epoch 491/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6270 - accuracy: 0.6721 - val_loss: 0.6162 - val_accuracy: 0.6721\n",
      "Epoch 492/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6270 - accuracy: 0.6721 - val_loss: 0.6162 - val_accuracy: 0.6721\n",
      "Epoch 493/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6269 - accuracy: 0.6721 - val_loss: 0.6161 - val_accuracy: 0.6721\n",
      "Epoch 494/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6269 - accuracy: 0.6721 - val_loss: 0.6161 - val_accuracy: 0.6721\n",
      "Epoch 495/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6268 - accuracy: 0.6721 - val_loss: 0.6161 - val_accuracy: 0.6721\n",
      "Epoch 496/500\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6268 - accuracy: 0.6721 - val_loss: 0.6160 - val_accuracy: 0.6721\n",
      "Epoch 497/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6268 - accuracy: 0.6721 - val_loss: 0.6160 - val_accuracy: 0.6721\n",
      "Epoch 498/500\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6267 - accuracy: 0.6721 - val_loss: 0.6159 - val_accuracy: 0.6721\n",
      "Epoch 499/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6267 - accuracy: 0.6721 - val_loss: 0.6159 - val_accuracy: 0.6721\n",
      "Epoch 500/500\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6266 - accuracy: 0.6721 - val_loss: 0.6159 - val_accuracy: 0.6721\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e5bec9b1c0>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model\n",
    "model = Sequential()\n",
    "\n",
    "# Model에 Layer 추가\n",
    "model.add(Flatten(input_shape=(2,)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Model 설정\n",
    "model.compile(optimizer=Adam(learning_rate=1e-3), loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Model 학습\n",
    "model.fit(x_data_train, t_data_train, epochs=500,\n",
    "          validation_split=0.2,\n",
    "          verbose=1)\n",
    "# validation_split=0.2\n",
    "#     metrics 와 연결되어있는 속성\n",
    "# verbose=1\n",
    "#     과정을 출력하기\n",
    "# 출력\n",
    "# 10/10 [==============================] - 0s 5ms/step - loss: 0.6143 - accuracy: 0.6754 - val_loss: 0.6022 - val_accuracy: 0.6883\n",
    "#     <keras.callbacks.History at 0x1e5bc346d90>\n",
    "#     val_accuracy 가 제일 중요하다. 0.68정도 이상으로는 올라가지 않네\n",
    "\n",
    "# Hyper Parameter 튜닝\n",
    "# 가장 좋은 솔루션을 찾아낼 때까지 이것저것 계속 바꿔보기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4a4906d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6549 - accuracy: 0.6234\n",
      "[0.6548946499824524, 0.6233766078948975]\n"
     ]
    }
   ],
   "source": [
    "# 평가하기\n",
    "# 위에서 여러가지 방법으로 (하이퍼 파라미터를 수정하는 방법) 모델을 완성시킨 후,\n",
    "# 최종적으로 우리 모델의 정확도를 계산한다.\n",
    "eval_result = model.evaluate(x_data_test, t_data_test)\n",
    "print(eval_result) # 출력 : [0.6548946499824524, 0.6233766078948975]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "597788f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.32131314]]\n"
     ]
    }
   ],
   "source": [
    "# 예측하기\n",
    "# 성적이 550, 3.5 일 때의 합격여부 알아보기\n",
    "\n",
    "# 정규화\n",
    "predict_data = np.array([[550.0, 3.5]])\n",
    "scaled_predict_data = scaler.transform(predict_data)\n",
    "result = model.predict(scaled_predict_data)\n",
    "print(result)\n",
    "# 출력 : [[0.32131314]]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_env] *",
   "language": "python",
   "name": "conda-env-data_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
