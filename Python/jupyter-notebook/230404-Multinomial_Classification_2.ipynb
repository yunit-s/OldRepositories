{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "848a25e9",
   "metadata": {},
   "source": [
    "# one-hot 작업이 번거로우니 이를 하지 않는 방법을 알아보자.\n",
    "\n",
    "포인트\n",
    "> model 설정할 때 loss에서 sparse_ 를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12856810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 module 불러오기\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# 학습데이터와 테스트데이터를 분리해야 한다. (7:3 혹은 8:2로 분리)\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 정규화\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# 우리 데이터에는 결측치와 이상치가 없다.\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f597ba0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>188</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>161</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>178</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>136</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  height  weight\n",
       "0      1     188      71\n",
       "1      2     161      68\n",
       "2      0     178      52\n",
       "3      2     136      63\n",
       "4      1     145      52"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(20000, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Raw Data Loading\n",
    "\n",
    "df = pd.read_csv('./data/bmi.csv', skiprows=3)\n",
    "display(df.head(), df.shape) # (20000, 3)\n",
    "\n",
    "# 결측치, 이상치는 따로 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb43d2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[196  66]\n",
      " [133  79]\n",
      " [133  52]\n",
      " ...\n",
      " [185  74]\n",
      " [124  78]\n",
      " [186  65]] (14000, 2)\n",
      "[[0.95       0.68888889]\n",
      " [0.1625     0.97777778]\n",
      " [0.1625     0.37777778]\n",
      " ...\n",
      " [0.8125     0.86666667]\n",
      " [0.05       0.95555556]\n",
      " [0.825      0.66666667]] (14000, 2)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 분리\n",
    "# 학습데이터와 테스트데이터를 분리\n",
    "\n",
    "x_data_train, x_data_test, t_data_train, t_data_test = \\\n",
    "train_test_split(df[['height', 'weight']].values,\n",
    "                df['label'].values,\n",
    "                test_size=0.3)\n",
    "# 원래는 train_test_split() 안에는 2차원 ndarray가 들어와야 하는데, 알아서 데이터 추출해서 사용한다.\n",
    "print(x_data_train, x_data_train.shape) # (14000, 2)\n",
    "# 6000개는 테스트, 14000개는 트레이닝 용으로 분류\n",
    "\n",
    "# 정규화\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_data_train)\n",
    "\n",
    "x_data_train_norm = scaler.transform(x_data_train)\n",
    "x_data_test_norm = scaler.transform(x_data_test)\n",
    "print(x_data_train_norm, x_data_train_norm.shape) # (14000, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c73b88fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "350/350 [==============================] - 1s 1ms/step - loss: 1.0162 - accuracy: 0.4326 - val_loss: 1.0088 - val_accuracy: 0.4614\n",
      "Epoch 2/300\n",
      "350/350 [==============================] - 0s 859us/step - loss: 1.0013 - accuracy: 0.4923 - val_loss: 0.9947 - val_accuracy: 0.5114\n",
      "Epoch 3/300\n",
      "350/350 [==============================] - 0s 899us/step - loss: 0.9880 - accuracy: 0.5436 - val_loss: 0.9821 - val_accuracy: 0.5575\n",
      "Epoch 4/300\n",
      "350/350 [==============================] - 0s 918us/step - loss: 0.9760 - accuracy: 0.5831 - val_loss: 0.9704 - val_accuracy: 0.5943\n",
      "Epoch 5/300\n",
      "350/350 [==============================] - 0s 868us/step - loss: 0.9649 - accuracy: 0.6138 - val_loss: 0.9597 - val_accuracy: 0.6264\n",
      "Epoch 6/300\n",
      "350/350 [==============================] - 0s 863us/step - loss: 0.9546 - accuracy: 0.6406 - val_loss: 0.9496 - val_accuracy: 0.6504\n",
      "Epoch 7/300\n",
      "350/350 [==============================] - 0s 878us/step - loss: 0.9449 - accuracy: 0.6599 - val_loss: 0.9402 - val_accuracy: 0.6686\n",
      "Epoch 8/300\n",
      "350/350 [==============================] - 0s 848us/step - loss: 0.9357 - accuracy: 0.6748 - val_loss: 0.9312 - val_accuracy: 0.6821\n",
      "Epoch 9/300\n",
      "350/350 [==============================] - 0s 858us/step - loss: 0.9270 - accuracy: 0.6853 - val_loss: 0.9227 - val_accuracy: 0.6904\n",
      "Epoch 10/300\n",
      "350/350 [==============================] - 0s 883us/step - loss: 0.9187 - accuracy: 0.6925 - val_loss: 0.9145 - val_accuracy: 0.6946\n",
      "Epoch 11/300\n",
      "350/350 [==============================] - 0s 891us/step - loss: 0.9107 - accuracy: 0.6979 - val_loss: 0.9067 - val_accuracy: 0.6968\n",
      "Epoch 12/300\n",
      "350/350 [==============================] - 0s 885us/step - loss: 0.9031 - accuracy: 0.7003 - val_loss: 0.8992 - val_accuracy: 0.6979\n",
      "Epoch 13/300\n",
      "350/350 [==============================] - 0s 901us/step - loss: 0.8958 - accuracy: 0.7003 - val_loss: 0.8920 - val_accuracy: 0.6968\n",
      "Epoch 14/300\n",
      "350/350 [==============================] - 0s 917us/step - loss: 0.8888 - accuracy: 0.7000 - val_loss: 0.8851 - val_accuracy: 0.6964\n",
      "Epoch 15/300\n",
      "350/350 [==============================] - 0s 903us/step - loss: 0.8820 - accuracy: 0.6993 - val_loss: 0.8783 - val_accuracy: 0.6964\n",
      "Epoch 16/300\n",
      "350/350 [==============================] - 0s 879us/step - loss: 0.8753 - accuracy: 0.6993 - val_loss: 0.8718 - val_accuracy: 0.6964\n",
      "Epoch 17/300\n",
      "350/350 [==============================] - 0s 935us/step - loss: 0.8688 - accuracy: 0.6993 - val_loss: 0.8653 - val_accuracy: 0.6964\n",
      "Epoch 18/300\n",
      "350/350 [==============================] - 0s 990us/step - loss: 0.8624 - accuracy: 0.6993 - val_loss: 0.8589 - val_accuracy: 0.6964\n",
      "Epoch 19/300\n",
      "350/350 [==============================] - 0s 881us/step - loss: 0.8562 - accuracy: 0.6993 - val_loss: 0.8528 - val_accuracy: 0.6964\n",
      "Epoch 20/300\n",
      "350/350 [==============================] - 0s 864us/step - loss: 0.8501 - accuracy: 0.6993 - val_loss: 0.8467 - val_accuracy: 0.6964\n",
      "Epoch 21/300\n",
      "350/350 [==============================] - 0s 869us/step - loss: 0.8441 - accuracy: 0.6993 - val_loss: 0.8407 - val_accuracy: 0.6975\n",
      "Epoch 22/300\n",
      "350/350 [==============================] - 0s 912us/step - loss: 0.8381 - accuracy: 0.7001 - val_loss: 0.8348 - val_accuracy: 0.6979\n",
      "Epoch 23/300\n",
      "350/350 [==============================] - 0s 907us/step - loss: 0.8323 - accuracy: 0.7003 - val_loss: 0.8290 - val_accuracy: 0.6982\n",
      "Epoch 24/300\n",
      "350/350 [==============================] - 0s 908us/step - loss: 0.8266 - accuracy: 0.7018 - val_loss: 0.8233 - val_accuracy: 0.6996\n",
      "Epoch 25/300\n",
      "350/350 [==============================] - 0s 900us/step - loss: 0.8209 - accuracy: 0.7047 - val_loss: 0.8177 - val_accuracy: 0.7075\n",
      "Epoch 26/300\n",
      "350/350 [==============================] - 0s 879us/step - loss: 0.8154 - accuracy: 0.7114 - val_loss: 0.8122 - val_accuracy: 0.7136\n",
      "Epoch 27/300\n",
      "350/350 [==============================] - 0s 847us/step - loss: 0.8099 - accuracy: 0.7181 - val_loss: 0.8068 - val_accuracy: 0.7164\n",
      "Epoch 28/300\n",
      "350/350 [==============================] - 0s 864us/step - loss: 0.8046 - accuracy: 0.7207 - val_loss: 0.8015 - val_accuracy: 0.7186\n",
      "Epoch 29/300\n",
      "350/350 [==============================] - 0s 875us/step - loss: 0.7993 - accuracy: 0.7230 - val_loss: 0.7963 - val_accuracy: 0.7218\n",
      "Epoch 30/300\n",
      "350/350 [==============================] - 0s 868us/step - loss: 0.7941 - accuracy: 0.7318 - val_loss: 0.7911 - val_accuracy: 0.7304\n",
      "Epoch 31/300\n",
      "350/350 [==============================] - 0s 861us/step - loss: 0.7890 - accuracy: 0.7375 - val_loss: 0.7860 - val_accuracy: 0.7396\n",
      "Epoch 32/300\n",
      "350/350 [==============================] - 0s 856us/step - loss: 0.7839 - accuracy: 0.7451 - val_loss: 0.7810 - val_accuracy: 0.7425\n",
      "Epoch 33/300\n",
      "350/350 [==============================] - 0s 913us/step - loss: 0.7789 - accuracy: 0.7480 - val_loss: 0.7761 - val_accuracy: 0.7468\n",
      "Epoch 34/300\n",
      "350/350 [==============================] - 0s 859us/step - loss: 0.7740 - accuracy: 0.7522 - val_loss: 0.7712 - val_accuracy: 0.7514\n",
      "Epoch 35/300\n",
      "350/350 [==============================] - 0s 875us/step - loss: 0.7692 - accuracy: 0.7601 - val_loss: 0.7664 - val_accuracy: 0.7539\n",
      "Epoch 36/300\n",
      "350/350 [==============================] - 0s 894us/step - loss: 0.7644 - accuracy: 0.7610 - val_loss: 0.7616 - val_accuracy: 0.7611\n",
      "Epoch 37/300\n",
      "350/350 [==============================] - 0s 887us/step - loss: 0.7596 - accuracy: 0.7684 - val_loss: 0.7569 - val_accuracy: 0.7671\n",
      "Epoch 38/300\n",
      "350/350 [==============================] - 0s 887us/step - loss: 0.7550 - accuracy: 0.7691 - val_loss: 0.7523 - val_accuracy: 0.7711\n",
      "Epoch 39/300\n",
      "350/350 [==============================] - 0s 893us/step - loss: 0.7504 - accuracy: 0.7730 - val_loss: 0.7477 - val_accuracy: 0.7768\n",
      "Epoch 40/300\n",
      "350/350 [==============================] - 0s 875us/step - loss: 0.7458 - accuracy: 0.7783 - val_loss: 0.7432 - val_accuracy: 0.7811\n",
      "Epoch 41/300\n",
      "350/350 [==============================] - 0s 877us/step - loss: 0.7414 - accuracy: 0.7833 - val_loss: 0.7388 - val_accuracy: 0.7850\n",
      "Epoch 42/300\n",
      "350/350 [==============================] - 0s 886us/step - loss: 0.7370 - accuracy: 0.7837 - val_loss: 0.7344 - val_accuracy: 0.7882\n",
      "Epoch 43/300\n",
      "350/350 [==============================] - 0s 912us/step - loss: 0.7326 - accuracy: 0.7896 - val_loss: 0.7301 - val_accuracy: 0.7907\n",
      "Epoch 44/300\n",
      "350/350 [==============================] - 0s 855us/step - loss: 0.7283 - accuracy: 0.7960 - val_loss: 0.7259 - val_accuracy: 0.7936\n",
      "Epoch 45/300\n",
      "350/350 [==============================] - 0s 898us/step - loss: 0.7241 - accuracy: 0.7973 - val_loss: 0.7217 - val_accuracy: 0.8004\n",
      "Epoch 46/300\n",
      "350/350 [==============================] - 0s 901us/step - loss: 0.7200 - accuracy: 0.8004 - val_loss: 0.7176 - val_accuracy: 0.8032\n",
      "Epoch 47/300\n",
      "350/350 [==============================] - 0s 897us/step - loss: 0.7159 - accuracy: 0.8000 - val_loss: 0.7136 - val_accuracy: 0.8071\n",
      "Epoch 48/300\n",
      "350/350 [==============================] - 0s 914us/step - loss: 0.7119 - accuracy: 0.8021 - val_loss: 0.7096 - val_accuracy: 0.8082\n",
      "Epoch 49/300\n",
      "350/350 [==============================] - 0s 870us/step - loss: 0.7079 - accuracy: 0.8077 - val_loss: 0.7056 - val_accuracy: 0.8089\n",
      "Epoch 50/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.7040 - accuracy: 0.8091 - val_loss: 0.7017 - val_accuracy: 0.8125\n",
      "Epoch 51/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.7001 - accuracy: 0.8117 - val_loss: 0.6979 - val_accuracy: 0.8139\n",
      "Epoch 52/300\n",
      "350/350 [==============================] - 0s 860us/step - loss: 0.6963 - accuracy: 0.8159 - val_loss: 0.6941 - val_accuracy: 0.8171\n",
      "Epoch 53/300\n",
      "350/350 [==============================] - 0s 866us/step - loss: 0.6925 - accuracy: 0.8175 - val_loss: 0.6903 - val_accuracy: 0.8189\n",
      "Epoch 54/300\n",
      "350/350 [==============================] - 0s 854us/step - loss: 0.6888 - accuracy: 0.8191 - val_loss: 0.6866 - val_accuracy: 0.8221\n",
      "Epoch 55/300\n",
      "350/350 [==============================] - 0s 866us/step - loss: 0.6852 - accuracy: 0.8220 - val_loss: 0.6830 - val_accuracy: 0.8232\n",
      "Epoch 56/300\n",
      "350/350 [==============================] - 0s 895us/step - loss: 0.6815 - accuracy: 0.8229 - val_loss: 0.6794 - val_accuracy: 0.8250\n",
      "Epoch 57/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 879us/step - loss: 0.6780 - accuracy: 0.8276 - val_loss: 0.6759 - val_accuracy: 0.8264\n",
      "Epoch 58/300\n",
      "350/350 [==============================] - 0s 851us/step - loss: 0.6744 - accuracy: 0.8286 - val_loss: 0.6723 - val_accuracy: 0.8279\n",
      "Epoch 59/300\n",
      "350/350 [==============================] - 0s 911us/step - loss: 0.6709 - accuracy: 0.8286 - val_loss: 0.6689 - val_accuracy: 0.8289\n",
      "Epoch 60/300\n",
      "350/350 [==============================] - 0s 867us/step - loss: 0.6675 - accuracy: 0.8317 - val_loss: 0.6654 - val_accuracy: 0.8289\n",
      "Epoch 61/300\n",
      "350/350 [==============================] - 0s 909us/step - loss: 0.6641 - accuracy: 0.8306 - val_loss: 0.6620 - val_accuracy: 0.8293\n",
      "Epoch 62/300\n",
      "350/350 [==============================] - 0s 866us/step - loss: 0.6607 - accuracy: 0.8340 - val_loss: 0.6587 - val_accuracy: 0.8318\n",
      "Epoch 63/300\n",
      "350/350 [==============================] - 0s 853us/step - loss: 0.6574 - accuracy: 0.8372 - val_loss: 0.6554 - val_accuracy: 0.8336\n",
      "Epoch 64/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.6541 - accuracy: 0.8379 - val_loss: 0.6522 - val_accuracy: 0.8379\n",
      "Epoch 65/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.6509 - accuracy: 0.8382 - val_loss: 0.6490 - val_accuracy: 0.8404\n",
      "Epoch 66/300\n",
      "350/350 [==============================] - 0s 942us/step - loss: 0.6477 - accuracy: 0.8421 - val_loss: 0.6458 - val_accuracy: 0.8421\n",
      "Epoch 67/300\n",
      "350/350 [==============================] - 0s 826us/step - loss: 0.6446 - accuracy: 0.8417 - val_loss: 0.6427 - val_accuracy: 0.8429\n",
      "Epoch 68/300\n",
      "350/350 [==============================] - 0s 903us/step - loss: 0.6415 - accuracy: 0.8449 - val_loss: 0.6397 - val_accuracy: 0.8439\n",
      "Epoch 69/300\n",
      "350/350 [==============================] - 0s 863us/step - loss: 0.6385 - accuracy: 0.8451 - val_loss: 0.6366 - val_accuracy: 0.8468\n",
      "Epoch 70/300\n",
      "350/350 [==============================] - 0s 880us/step - loss: 0.6355 - accuracy: 0.8451 - val_loss: 0.6336 - val_accuracy: 0.8479\n",
      "Epoch 71/300\n",
      "350/350 [==============================] - 0s 851us/step - loss: 0.6325 - accuracy: 0.8480 - val_loss: 0.6307 - val_accuracy: 0.8489\n",
      "Epoch 72/300\n",
      "350/350 [==============================] - 0s 922us/step - loss: 0.6295 - accuracy: 0.8492 - val_loss: 0.6277 - val_accuracy: 0.8507\n",
      "Epoch 73/300\n",
      "350/350 [==============================] - 0s 909us/step - loss: 0.6266 - accuracy: 0.8493 - val_loss: 0.6248 - val_accuracy: 0.8496\n",
      "Epoch 74/300\n",
      "350/350 [==============================] - 0s 876us/step - loss: 0.6237 - accuracy: 0.8497 - val_loss: 0.6219 - val_accuracy: 0.8507\n",
      "Epoch 75/300\n",
      "350/350 [==============================] - 0s 932us/step - loss: 0.6208 - accuracy: 0.8507 - val_loss: 0.6191 - val_accuracy: 0.8518\n",
      "Epoch 76/300\n",
      "350/350 [==============================] - 0s 945us/step - loss: 0.6180 - accuracy: 0.8505 - val_loss: 0.6163 - val_accuracy: 0.8543\n",
      "Epoch 77/300\n",
      "350/350 [==============================] - 0s 917us/step - loss: 0.6152 - accuracy: 0.8556 - val_loss: 0.6135 - val_accuracy: 0.8554\n",
      "Epoch 78/300\n",
      "350/350 [==============================] - 0s 868us/step - loss: 0.6125 - accuracy: 0.8571 - val_loss: 0.6108 - val_accuracy: 0.8557\n",
      "Epoch 79/300\n",
      "350/350 [==============================] - 0s 901us/step - loss: 0.6098 - accuracy: 0.8566 - val_loss: 0.6081 - val_accuracy: 0.8554\n",
      "Epoch 80/300\n",
      "350/350 [==============================] - 0s 904us/step - loss: 0.6071 - accuracy: 0.8576 - val_loss: 0.6054 - val_accuracy: 0.8564\n",
      "Epoch 81/300\n",
      "350/350 [==============================] - 0s 913us/step - loss: 0.6044 - accuracy: 0.8579 - val_loss: 0.6028 - val_accuracy: 0.8582\n",
      "Epoch 82/300\n",
      "350/350 [==============================] - 0s 942us/step - loss: 0.6018 - accuracy: 0.8590 - val_loss: 0.6001 - val_accuracy: 0.8582\n",
      "Epoch 83/300\n",
      "350/350 [==============================] - 0s 838us/step - loss: 0.5992 - accuracy: 0.8596 - val_loss: 0.5976 - val_accuracy: 0.8593\n",
      "Epoch 84/300\n",
      "350/350 [==============================] - 0s 863us/step - loss: 0.5966 - accuracy: 0.8597 - val_loss: 0.5950 - val_accuracy: 0.8596\n",
      "Epoch 85/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.5941 - accuracy: 0.8606 - val_loss: 0.5926 - val_accuracy: 0.8607\n",
      "Epoch 86/300\n",
      "350/350 [==============================] - 0s 872us/step - loss: 0.5917 - accuracy: 0.8613 - val_loss: 0.5901 - val_accuracy: 0.8618\n",
      "Epoch 87/300\n",
      "350/350 [==============================] - 0s 936us/step - loss: 0.5892 - accuracy: 0.8625 - val_loss: 0.5877 - val_accuracy: 0.8618\n",
      "Epoch 88/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.5868 - accuracy: 0.8645 - val_loss: 0.5853 - val_accuracy: 0.8629\n",
      "Epoch 89/300\n",
      "350/350 [==============================] - 0s 958us/step - loss: 0.5844 - accuracy: 0.8645 - val_loss: 0.5829 - val_accuracy: 0.8643\n",
      "Epoch 90/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.5821 - accuracy: 0.8655 - val_loss: 0.5806 - val_accuracy: 0.8654\n",
      "Epoch 91/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.5797 - accuracy: 0.8662 - val_loss: 0.5782 - val_accuracy: 0.8654\n",
      "Epoch 92/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.5774 - accuracy: 0.8683 - val_loss: 0.5759 - val_accuracy: 0.8654\n",
      "Epoch 93/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.5751 - accuracy: 0.8681 - val_loss: 0.5736 - val_accuracy: 0.8657\n",
      "Epoch 94/300\n",
      "350/350 [==============================] - 0s 878us/step - loss: 0.5728 - accuracy: 0.8684 - val_loss: 0.5713 - val_accuracy: 0.8661\n",
      "Epoch 95/300\n",
      "350/350 [==============================] - 0s 882us/step - loss: 0.5705 - accuracy: 0.8688 - val_loss: 0.5690 - val_accuracy: 0.8671\n",
      "Epoch 96/300\n",
      "350/350 [==============================] - 0s 871us/step - loss: 0.5683 - accuracy: 0.8697 - val_loss: 0.5668 - val_accuracy: 0.8679\n",
      "Epoch 97/300\n",
      "350/350 [==============================] - 0s 966us/step - loss: 0.5660 - accuracy: 0.8708 - val_loss: 0.5646 - val_accuracy: 0.8682\n",
      "Epoch 98/300\n",
      "350/350 [==============================] - 0s 967us/step - loss: 0.5638 - accuracy: 0.8707 - val_loss: 0.5624 - val_accuracy: 0.8696\n",
      "Epoch 99/300\n",
      "350/350 [==============================] - 0s 951us/step - loss: 0.5616 - accuracy: 0.8712 - val_loss: 0.5602 - val_accuracy: 0.8704\n",
      "Epoch 100/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.5595 - accuracy: 0.8721 - val_loss: 0.5581 - val_accuracy: 0.8711\n",
      "Epoch 101/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.5574 - accuracy: 0.8741 - val_loss: 0.5560 - val_accuracy: 0.8721\n",
      "Epoch 102/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.5553 - accuracy: 0.8746 - val_loss: 0.5539 - val_accuracy: 0.8739\n",
      "Epoch 103/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.5532 - accuracy: 0.8769 - val_loss: 0.5518 - val_accuracy: 0.8754\n",
      "Epoch 104/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.5512 - accuracy: 0.8773 - val_loss: 0.5498 - val_accuracy: 0.8771\n",
      "Epoch 105/300\n",
      "350/350 [==============================] - 0s 995us/step - loss: 0.5492 - accuracy: 0.8796 - val_loss: 0.5478 - val_accuracy: 0.8782\n",
      "Epoch 106/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.5472 - accuracy: 0.8794 - val_loss: 0.5458 - val_accuracy: 0.8782\n",
      "Epoch 107/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.5452 - accuracy: 0.8801 - val_loss: 0.5438 - val_accuracy: 0.8782\n",
      "Epoch 108/300\n",
      "350/350 [==============================] - 0s 999us/step - loss: 0.5432 - accuracy: 0.8797 - val_loss: 0.5419 - val_accuracy: 0.8782\n",
      "Epoch 109/300\n",
      "350/350 [==============================] - 0s 949us/step - loss: 0.5413 - accuracy: 0.8810 - val_loss: 0.5399 - val_accuracy: 0.8782\n",
      "Epoch 110/300\n",
      "350/350 [==============================] - 0s 939us/step - loss: 0.5394 - accuracy: 0.8810 - val_loss: 0.5380 - val_accuracy: 0.8782\n",
      "Epoch 111/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.5374 - accuracy: 0.8811 - val_loss: 0.5361 - val_accuracy: 0.8779\n",
      "Epoch 112/300\n",
      "350/350 [==============================] - 0s 984us/step - loss: 0.5356 - accuracy: 0.8815 - val_loss: 0.5342 - val_accuracy: 0.8779\n",
      "Epoch 113/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 1ms/step - loss: 0.5337 - accuracy: 0.8813 - val_loss: 0.5324 - val_accuracy: 0.8789\n",
      "Epoch 114/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.5318 - accuracy: 0.8811 - val_loss: 0.5305 - val_accuracy: 0.8789\n",
      "Epoch 115/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.5300 - accuracy: 0.8816 - val_loss: 0.5287 - val_accuracy: 0.8789\n",
      "Epoch 116/300\n",
      "350/350 [==============================] - 0s 942us/step - loss: 0.5282 - accuracy: 0.8815 - val_loss: 0.5269 - val_accuracy: 0.8789\n",
      "Epoch 117/300\n",
      "350/350 [==============================] - 0s 940us/step - loss: 0.5264 - accuracy: 0.8817 - val_loss: 0.5250 - val_accuracy: 0.8800\n",
      "Epoch 118/300\n",
      "350/350 [==============================] - 0s 923us/step - loss: 0.5245 - accuracy: 0.8814 - val_loss: 0.5232 - val_accuracy: 0.8786\n",
      "Epoch 119/300\n",
      "350/350 [==============================] - 0s 909us/step - loss: 0.5227 - accuracy: 0.8814 - val_loss: 0.5214 - val_accuracy: 0.8789\n",
      "Epoch 120/300\n",
      "350/350 [==============================] - 0s 953us/step - loss: 0.5210 - accuracy: 0.8821 - val_loss: 0.5197 - val_accuracy: 0.8811\n",
      "Epoch 121/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.5192 - accuracy: 0.8871 - val_loss: 0.5179 - val_accuracy: 0.8843\n",
      "Epoch 122/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.5175 - accuracy: 0.8863 - val_loss: 0.5162 - val_accuracy: 0.8843\n",
      "Epoch 123/300\n",
      "350/350 [==============================] - 0s 940us/step - loss: 0.5158 - accuracy: 0.8890 - val_loss: 0.5145 - val_accuracy: 0.8843\n",
      "Epoch 124/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.5141 - accuracy: 0.8887 - val_loss: 0.5128 - val_accuracy: 0.8843\n",
      "Epoch 125/300\n",
      "350/350 [==============================] - 0s 985us/step - loss: 0.5124 - accuracy: 0.8891 - val_loss: 0.5111 - val_accuracy: 0.8846\n",
      "Epoch 126/300\n",
      "350/350 [==============================] - 0s 940us/step - loss: 0.5107 - accuracy: 0.8889 - val_loss: 0.5095 - val_accuracy: 0.8846\n",
      "Epoch 127/300\n",
      "350/350 [==============================] - 0s 895us/step - loss: 0.5091 - accuracy: 0.8888 - val_loss: 0.5078 - val_accuracy: 0.8843\n",
      "Epoch 128/300\n",
      "350/350 [==============================] - 0s 908us/step - loss: 0.5075 - accuracy: 0.8890 - val_loss: 0.5062 - val_accuracy: 0.8846\n",
      "Epoch 129/300\n",
      "350/350 [==============================] - 0s 842us/step - loss: 0.5059 - accuracy: 0.8889 - val_loss: 0.5046 - val_accuracy: 0.8843\n",
      "Epoch 130/300\n",
      "350/350 [==============================] - 0s 864us/step - loss: 0.5043 - accuracy: 0.8891 - val_loss: 0.5030 - val_accuracy: 0.8843\n",
      "Epoch 131/300\n",
      "350/350 [==============================] - 0s 908us/step - loss: 0.5027 - accuracy: 0.8896 - val_loss: 0.5015 - val_accuracy: 0.8843\n",
      "Epoch 132/300\n",
      "350/350 [==============================] - 0s 953us/step - loss: 0.5011 - accuracy: 0.8894 - val_loss: 0.4999 - val_accuracy: 0.8843\n",
      "Epoch 133/300\n",
      "350/350 [==============================] - 0s 940us/step - loss: 0.4996 - accuracy: 0.8892 - val_loss: 0.4984 - val_accuracy: 0.8843\n",
      "Epoch 134/300\n",
      "350/350 [==============================] - 0s 895us/step - loss: 0.4980 - accuracy: 0.8897 - val_loss: 0.4968 - val_accuracy: 0.8857\n",
      "Epoch 135/300\n",
      "350/350 [==============================] - 0s 913us/step - loss: 0.4965 - accuracy: 0.8899 - val_loss: 0.4953 - val_accuracy: 0.8857\n",
      "Epoch 136/300\n",
      "350/350 [==============================] - 0s 831us/step - loss: 0.4950 - accuracy: 0.8899 - val_loss: 0.4938 - val_accuracy: 0.8857\n",
      "Epoch 137/300\n",
      "350/350 [==============================] - 0s 899us/step - loss: 0.4935 - accuracy: 0.8905 - val_loss: 0.4923 - val_accuracy: 0.8861\n",
      "Epoch 138/300\n",
      "350/350 [==============================] - 0s 895us/step - loss: 0.4920 - accuracy: 0.8901 - val_loss: 0.4908 - val_accuracy: 0.8864\n",
      "Epoch 139/300\n",
      "350/350 [==============================] - 0s 955us/step - loss: 0.4906 - accuracy: 0.8906 - val_loss: 0.4893 - val_accuracy: 0.8864\n",
      "Epoch 140/300\n",
      "350/350 [==============================] - 0s 867us/step - loss: 0.4891 - accuracy: 0.8907 - val_loss: 0.4879 - val_accuracy: 0.8882\n",
      "Epoch 141/300\n",
      "350/350 [==============================] - 0s 863us/step - loss: 0.4877 - accuracy: 0.8931 - val_loss: 0.4865 - val_accuracy: 0.8893\n",
      "Epoch 142/300\n",
      "350/350 [==============================] - 0s 940us/step - loss: 0.4863 - accuracy: 0.8938 - val_loss: 0.4851 - val_accuracy: 0.8900\n",
      "Epoch 143/300\n",
      "350/350 [==============================] - 0s 958us/step - loss: 0.4848 - accuracy: 0.8936 - val_loss: 0.4836 - val_accuracy: 0.8900\n",
      "Epoch 144/300\n",
      "350/350 [==============================] - 0s 895us/step - loss: 0.4834 - accuracy: 0.8938 - val_loss: 0.4822 - val_accuracy: 0.8914\n",
      "Epoch 145/300\n",
      "350/350 [==============================] - 0s 954us/step - loss: 0.4820 - accuracy: 0.8950 - val_loss: 0.4808 - val_accuracy: 0.8925\n",
      "Epoch 146/300\n",
      "350/350 [==============================] - 0s 954us/step - loss: 0.4806 - accuracy: 0.8955 - val_loss: 0.4794 - val_accuracy: 0.8932\n",
      "Epoch 147/300\n",
      "350/350 [==============================] - 0s 985us/step - loss: 0.4793 - accuracy: 0.8963 - val_loss: 0.4780 - val_accuracy: 0.8943\n",
      "Epoch 148/300\n",
      "350/350 [==============================] - 0s 955us/step - loss: 0.4779 - accuracy: 0.8975 - val_loss: 0.4767 - val_accuracy: 0.8950\n",
      "Epoch 149/300\n",
      "350/350 [==============================] - 0s 908us/step - loss: 0.4765 - accuracy: 0.8982 - val_loss: 0.4753 - val_accuracy: 0.8957\n",
      "Epoch 150/300\n",
      "350/350 [==============================] - 0s 940us/step - loss: 0.4752 - accuracy: 0.8986 - val_loss: 0.4740 - val_accuracy: 0.8964\n",
      "Epoch 151/300\n",
      "350/350 [==============================] - 0s 919us/step - loss: 0.4738 - accuracy: 0.8983 - val_loss: 0.4726 - val_accuracy: 0.8971\n",
      "Epoch 152/300\n",
      "350/350 [==============================] - 0s 930us/step - loss: 0.4725 - accuracy: 0.8988 - val_loss: 0.4713 - val_accuracy: 0.8975\n",
      "Epoch 153/300\n",
      "350/350 [==============================] - 0s 846us/step - loss: 0.4712 - accuracy: 0.8996 - val_loss: 0.4700 - val_accuracy: 0.8975\n",
      "Epoch 154/300\n",
      "350/350 [==============================] - 0s 863us/step - loss: 0.4699 - accuracy: 0.8995 - val_loss: 0.4687 - val_accuracy: 0.8982\n",
      "Epoch 155/300\n",
      "350/350 [==============================] - 0s 914us/step - loss: 0.4686 - accuracy: 0.9006 - val_loss: 0.4674 - val_accuracy: 0.8982\n",
      "Epoch 156/300\n",
      "350/350 [==============================] - 0s 985us/step - loss: 0.4673 - accuracy: 0.9009 - val_loss: 0.4661 - val_accuracy: 0.8982\n",
      "Epoch 157/300\n",
      "350/350 [==============================] - 0s 895us/step - loss: 0.4661 - accuracy: 0.9008 - val_loss: 0.4648 - val_accuracy: 0.8986\n",
      "Epoch 158/300\n",
      "350/350 [==============================] - 0s 909us/step - loss: 0.4648 - accuracy: 0.9010 - val_loss: 0.4636 - val_accuracy: 0.8996\n",
      "Epoch 159/300\n",
      "350/350 [==============================] - 0s 851us/step - loss: 0.4635 - accuracy: 0.9014 - val_loss: 0.4623 - val_accuracy: 0.9000\n",
      "Epoch 160/300\n",
      "350/350 [==============================] - 0s 851us/step - loss: 0.4623 - accuracy: 0.9018 - val_loss: 0.4611 - val_accuracy: 0.9007\n",
      "Epoch 161/300\n",
      "350/350 [==============================] - 0s 940us/step - loss: 0.4610 - accuracy: 0.9023 - val_loss: 0.4598 - val_accuracy: 0.9007\n",
      "Epoch 162/300\n",
      "350/350 [==============================] - 0s 979us/step - loss: 0.4598 - accuracy: 0.9028 - val_loss: 0.4586 - val_accuracy: 0.9011\n",
      "Epoch 163/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4586 - accuracy: 0.9033 - val_loss: 0.4574 - val_accuracy: 0.9014\n",
      "Epoch 164/300\n",
      "350/350 [==============================] - 0s 907us/step - loss: 0.4574 - accuracy: 0.9038 - val_loss: 0.4562 - val_accuracy: 0.9021\n",
      "Epoch 165/300\n",
      "350/350 [==============================] - 0s 946us/step - loss: 0.4562 - accuracy: 0.9047 - val_loss: 0.4550 - val_accuracy: 0.9021\n",
      "Epoch 166/300\n",
      "350/350 [==============================] - 0s 953us/step - loss: 0.4550 - accuracy: 0.9051 - val_loss: 0.4538 - val_accuracy: 0.9036\n",
      "Epoch 167/300\n",
      "350/350 [==============================] - 0s 993us/step - loss: 0.4538 - accuracy: 0.9053 - val_loss: 0.4526 - val_accuracy: 0.9036\n",
      "Epoch 168/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4526 - accuracy: 0.9059 - val_loss: 0.4514 - val_accuracy: 0.9036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4515 - accuracy: 0.9063 - val_loss: 0.4502 - val_accuracy: 0.9039\n",
      "Epoch 170/300\n",
      "350/350 [==============================] - 0s 953us/step - loss: 0.4503 - accuracy: 0.9066 - val_loss: 0.4491 - val_accuracy: 0.9043\n",
      "Epoch 171/300\n",
      "350/350 [==============================] - 0s 901us/step - loss: 0.4492 - accuracy: 0.9067 - val_loss: 0.4479 - val_accuracy: 0.9046\n",
      "Epoch 172/300\n",
      "350/350 [==============================] - 0s 873us/step - loss: 0.4480 - accuracy: 0.9072 - val_loss: 0.4468 - val_accuracy: 0.9046\n",
      "Epoch 173/300\n",
      "350/350 [==============================] - 0s 918us/step - loss: 0.4469 - accuracy: 0.9072 - val_loss: 0.4457 - val_accuracy: 0.9043\n",
      "Epoch 174/300\n",
      "350/350 [==============================] - 0s 952us/step - loss: 0.4458 - accuracy: 0.9077 - val_loss: 0.4445 - val_accuracy: 0.9046\n",
      "Epoch 175/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4446 - accuracy: 0.9078 - val_loss: 0.4434 - val_accuracy: 0.9050\n",
      "Epoch 176/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4435 - accuracy: 0.9079 - val_loss: 0.4423 - val_accuracy: 0.9064\n",
      "Epoch 177/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4424 - accuracy: 0.9083 - val_loss: 0.4412 - val_accuracy: 0.9071\n",
      "Epoch 178/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4413 - accuracy: 0.9084 - val_loss: 0.4401 - val_accuracy: 0.9071\n",
      "Epoch 179/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4403 - accuracy: 0.9092 - val_loss: 0.4390 - val_accuracy: 0.9079\n",
      "Epoch 180/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4392 - accuracy: 0.9097 - val_loss: 0.4379 - val_accuracy: 0.9086\n",
      "Epoch 181/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4381 - accuracy: 0.9104 - val_loss: 0.4369 - val_accuracy: 0.9086\n",
      "Epoch 182/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4370 - accuracy: 0.9101 - val_loss: 0.4358 - val_accuracy: 0.9086\n",
      "Epoch 183/300\n",
      "350/350 [==============================] - 0s 998us/step - loss: 0.4360 - accuracy: 0.9107 - val_loss: 0.4347 - val_accuracy: 0.9093\n",
      "Epoch 184/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4349 - accuracy: 0.9113 - val_loss: 0.4337 - val_accuracy: 0.9093\n",
      "Epoch 185/300\n",
      "350/350 [==============================] - 0s 985us/step - loss: 0.4339 - accuracy: 0.9116 - val_loss: 0.4326 - val_accuracy: 0.9093\n",
      "Epoch 186/300\n",
      "350/350 [==============================] - 0s 992us/step - loss: 0.4329 - accuracy: 0.9123 - val_loss: 0.4316 - val_accuracy: 0.9104\n",
      "Epoch 187/300\n",
      "350/350 [==============================] - 0s 991us/step - loss: 0.4318 - accuracy: 0.9124 - val_loss: 0.4306 - val_accuracy: 0.9104\n",
      "Epoch 188/300\n",
      "350/350 [==============================] - 0s 966us/step - loss: 0.4308 - accuracy: 0.9127 - val_loss: 0.4295 - val_accuracy: 0.9104\n",
      "Epoch 189/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4298 - accuracy: 0.9127 - val_loss: 0.4285 - val_accuracy: 0.9107\n",
      "Epoch 190/300\n",
      "350/350 [==============================] - 0s 1000us/step - loss: 0.4288 - accuracy: 0.9133 - val_loss: 0.4275 - val_accuracy: 0.9121\n",
      "Epoch 191/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.9137 - val_loss: 0.4265 - val_accuracy: 0.9121\n",
      "Epoch 192/300\n",
      "350/350 [==============================] - 0s 999us/step - loss: 0.4268 - accuracy: 0.9137 - val_loss: 0.4255 - val_accuracy: 0.9129\n",
      "Epoch 193/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4258 - accuracy: 0.9143 - val_loss: 0.4245 - val_accuracy: 0.9139\n",
      "Epoch 194/300\n",
      "350/350 [==============================] - 0s 987us/step - loss: 0.4249 - accuracy: 0.9142 - val_loss: 0.4236 - val_accuracy: 0.9139\n",
      "Epoch 195/300\n",
      "350/350 [==============================] - 0s 963us/step - loss: 0.4239 - accuracy: 0.9151 - val_loss: 0.4226 - val_accuracy: 0.9143\n",
      "Epoch 196/300\n",
      "350/350 [==============================] - 0s 998us/step - loss: 0.4229 - accuracy: 0.9146 - val_loss: 0.4216 - val_accuracy: 0.9143\n",
      "Epoch 197/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4220 - accuracy: 0.9150 - val_loss: 0.4207 - val_accuracy: 0.9146\n",
      "Epoch 198/300\n",
      "350/350 [==============================] - 0s 973us/step - loss: 0.4210 - accuracy: 0.9155 - val_loss: 0.4197 - val_accuracy: 0.9154\n",
      "Epoch 199/300\n",
      "350/350 [==============================] - 0s 972us/step - loss: 0.4201 - accuracy: 0.9161 - val_loss: 0.4187 - val_accuracy: 0.9157\n",
      "Epoch 200/300\n",
      "350/350 [==============================] - 0s 950us/step - loss: 0.4191 - accuracy: 0.9167 - val_loss: 0.4178 - val_accuracy: 0.9161\n",
      "Epoch 201/300\n",
      "350/350 [==============================] - 0s 967us/step - loss: 0.4182 - accuracy: 0.9170 - val_loss: 0.4169 - val_accuracy: 0.9164\n",
      "Epoch 202/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4172 - accuracy: 0.9173 - val_loss: 0.4159 - val_accuracy: 0.9168\n",
      "Epoch 203/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4163 - accuracy: 0.9184 - val_loss: 0.4150 - val_accuracy: 0.9168\n",
      "Epoch 204/300\n",
      "350/350 [==============================] - 0s 983us/step - loss: 0.4154 - accuracy: 0.9191 - val_loss: 0.4141 - val_accuracy: 0.9182\n",
      "Epoch 205/300\n",
      "350/350 [==============================] - 0s 979us/step - loss: 0.4145 - accuracy: 0.9196 - val_loss: 0.4131 - val_accuracy: 0.9189\n",
      "Epoch 206/300\n",
      "350/350 [==============================] - 0s 944us/step - loss: 0.4136 - accuracy: 0.9207 - val_loss: 0.4122 - val_accuracy: 0.9200\n",
      "Epoch 207/300\n",
      "350/350 [==============================] - 0s 965us/step - loss: 0.4127 - accuracy: 0.9195 - val_loss: 0.4113 - val_accuracy: 0.9211\n",
      "Epoch 208/300\n",
      "350/350 [==============================] - 0s 938us/step - loss: 0.4118 - accuracy: 0.9198 - val_loss: 0.4104 - val_accuracy: 0.9214\n",
      "Epoch 209/300\n",
      "350/350 [==============================] - 0s 950us/step - loss: 0.4109 - accuracy: 0.9207 - val_loss: 0.4095 - val_accuracy: 0.9214\n",
      "Epoch 210/300\n",
      "350/350 [==============================] - 0s 952us/step - loss: 0.4100 - accuracy: 0.9210 - val_loss: 0.4087 - val_accuracy: 0.9214\n",
      "Epoch 211/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4091 - accuracy: 0.9204 - val_loss: 0.4078 - val_accuracy: 0.9214\n",
      "Epoch 212/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4082 - accuracy: 0.9210 - val_loss: 0.4069 - val_accuracy: 0.9218\n",
      "Epoch 213/300\n",
      "350/350 [==============================] - 0s 954us/step - loss: 0.4074 - accuracy: 0.9209 - val_loss: 0.4060 - val_accuracy: 0.9218\n",
      "Epoch 214/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4065 - accuracy: 0.9212 - val_loss: 0.4051 - val_accuracy: 0.9218\n",
      "Epoch 215/300\n",
      "350/350 [==============================] - 0s 980us/step - loss: 0.4056 - accuracy: 0.9210 - val_loss: 0.4043 - val_accuracy: 0.9221\n",
      "Epoch 216/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4048 - accuracy: 0.9212 - val_loss: 0.4034 - val_accuracy: 0.9221\n",
      "Epoch 217/300\n",
      "350/350 [==============================] - 0s 947us/step - loss: 0.4039 - accuracy: 0.9213 - val_loss: 0.4025 - val_accuracy: 0.9221\n",
      "Epoch 218/300\n",
      "350/350 [==============================] - 0s 982us/step - loss: 0.4030 - accuracy: 0.9212 - val_loss: 0.4017 - val_accuracy: 0.9229\n",
      "Epoch 219/300\n",
      "350/350 [==============================] - 0s 935us/step - loss: 0.4022 - accuracy: 0.9213 - val_loss: 0.4008 - val_accuracy: 0.9236\n",
      "Epoch 220/300\n",
      "350/350 [==============================] - 0s 996us/step - loss: 0.4014 - accuracy: 0.9221 - val_loss: 0.4000 - val_accuracy: 0.9229\n",
      "Epoch 221/300\n",
      "350/350 [==============================] - 0s 932us/step - loss: 0.4005 - accuracy: 0.9215 - val_loss: 0.3991 - val_accuracy: 0.9225\n",
      "Epoch 222/300\n",
      "350/350 [==============================] - 0s 952us/step - loss: 0.3997 - accuracy: 0.9224 - val_loss: 0.3983 - val_accuracy: 0.9229\n",
      "Epoch 223/300\n",
      "350/350 [==============================] - 0s 969us/step - loss: 0.3989 - accuracy: 0.9227 - val_loss: 0.3975 - val_accuracy: 0.9232\n",
      "Epoch 224/300\n",
      "350/350 [==============================] - 0s 988us/step - loss: 0.3981 - accuracy: 0.9222 - val_loss: 0.3967 - val_accuracy: 0.9232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/300\n",
      "350/350 [==============================] - 0s 965us/step - loss: 0.3972 - accuracy: 0.9225 - val_loss: 0.3958 - val_accuracy: 0.9232\n",
      "Epoch 226/300\n",
      "350/350 [==============================] - 0s 969us/step - loss: 0.3964 - accuracy: 0.9244 - val_loss: 0.3950 - val_accuracy: 0.9243\n",
      "Epoch 227/300\n",
      "350/350 [==============================] - 0s 942us/step - loss: 0.3956 - accuracy: 0.9246 - val_loss: 0.3942 - val_accuracy: 0.9293\n",
      "Epoch 228/300\n",
      "350/350 [==============================] - 0s 950us/step - loss: 0.3948 - accuracy: 0.9287 - val_loss: 0.3934 - val_accuracy: 0.9311\n",
      "Epoch 229/300\n",
      "350/350 [==============================] - 0s 951us/step - loss: 0.3940 - accuracy: 0.9305 - val_loss: 0.3926 - val_accuracy: 0.9304\n",
      "Epoch 230/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3933 - accuracy: 0.9298 - val_loss: 0.3918 - val_accuracy: 0.9307\n",
      "Epoch 231/300\n",
      "350/350 [==============================] - 0s 980us/step - loss: 0.3925 - accuracy: 0.9310 - val_loss: 0.3911 - val_accuracy: 0.9314\n",
      "Epoch 232/300\n",
      "350/350 [==============================] - 0s 972us/step - loss: 0.3917 - accuracy: 0.9290 - val_loss: 0.3903 - val_accuracy: 0.9314\n",
      "Epoch 233/300\n",
      "350/350 [==============================] - 0s 975us/step - loss: 0.3909 - accuracy: 0.9319 - val_loss: 0.3895 - val_accuracy: 0.9318\n",
      "Epoch 234/300\n",
      "350/350 [==============================] - 0s 935us/step - loss: 0.3902 - accuracy: 0.9301 - val_loss: 0.3887 - val_accuracy: 0.9314\n",
      "Epoch 235/300\n",
      "350/350 [==============================] - 0s 959us/step - loss: 0.3894 - accuracy: 0.9302 - val_loss: 0.3880 - val_accuracy: 0.9321\n",
      "Epoch 236/300\n",
      "350/350 [==============================] - 0s 973us/step - loss: 0.3887 - accuracy: 0.9325 - val_loss: 0.3872 - val_accuracy: 0.9332\n",
      "Epoch 237/300\n",
      "350/350 [==============================] - 0s 984us/step - loss: 0.3879 - accuracy: 0.9320 - val_loss: 0.3865 - val_accuracy: 0.9332\n",
      "Epoch 238/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.9310 - val_loss: 0.3858 - val_accuracy: 0.9336\n",
      "Epoch 239/300\n",
      "350/350 [==============================] - 0s 991us/step - loss: 0.3865 - accuracy: 0.9323 - val_loss: 0.3850 - val_accuracy: 0.9336\n",
      "Epoch 240/300\n",
      "350/350 [==============================] - 0s 938us/step - loss: 0.3858 - accuracy: 0.9325 - val_loss: 0.3843 - val_accuracy: 0.9332\n",
      "Epoch 241/300\n",
      "350/350 [==============================] - 0s 978us/step - loss: 0.3850 - accuracy: 0.9325 - val_loss: 0.3836 - val_accuracy: 0.9332\n",
      "Epoch 242/300\n",
      "350/350 [==============================] - 0s 948us/step - loss: 0.3843 - accuracy: 0.9324 - val_loss: 0.3828 - val_accuracy: 0.9339\n",
      "Epoch 243/300\n",
      "350/350 [==============================] - 0s 973us/step - loss: 0.3836 - accuracy: 0.9323 - val_loss: 0.3821 - val_accuracy: 0.9343\n",
      "Epoch 244/300\n",
      "350/350 [==============================] - 0s 927us/step - loss: 0.3829 - accuracy: 0.9331 - val_loss: 0.3814 - val_accuracy: 0.9346\n",
      "Epoch 245/300\n",
      "350/350 [==============================] - 0s 956us/step - loss: 0.3822 - accuracy: 0.9330 - val_loss: 0.3807 - val_accuracy: 0.9343\n",
      "Epoch 246/300\n",
      "350/350 [==============================] - 0s 978us/step - loss: 0.3814 - accuracy: 0.9333 - val_loss: 0.3800 - val_accuracy: 0.9339\n",
      "Epoch 247/300\n",
      "350/350 [==============================] - 0s 980us/step - loss: 0.3807 - accuracy: 0.9337 - val_loss: 0.3793 - val_accuracy: 0.9339\n",
      "Epoch 248/300\n",
      "350/350 [==============================] - 0s 964us/step - loss: 0.3800 - accuracy: 0.9341 - val_loss: 0.3785 - val_accuracy: 0.9343\n",
      "Epoch 249/300\n",
      "350/350 [==============================] - 0s 932us/step - loss: 0.3793 - accuracy: 0.9334 - val_loss: 0.3778 - val_accuracy: 0.9343\n",
      "Epoch 250/300\n",
      "350/350 [==============================] - 0s 958us/step - loss: 0.3786 - accuracy: 0.9337 - val_loss: 0.3771 - val_accuracy: 0.9343\n",
      "Epoch 251/300\n",
      "350/350 [==============================] - 0s 948us/step - loss: 0.3779 - accuracy: 0.9338 - val_loss: 0.3764 - val_accuracy: 0.9346\n",
      "Epoch 252/300\n",
      "350/350 [==============================] - 0s 952us/step - loss: 0.3772 - accuracy: 0.9344 - val_loss: 0.3757 - val_accuracy: 0.9354\n",
      "Epoch 253/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3765 - accuracy: 0.9344 - val_loss: 0.3750 - val_accuracy: 0.9350\n",
      "Epoch 254/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3758 - accuracy: 0.9351 - val_loss: 0.3743 - val_accuracy: 0.9350\n",
      "Epoch 255/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3752 - accuracy: 0.9353 - val_loss: 0.3736 - val_accuracy: 0.9354\n",
      "Epoch 256/300\n",
      "350/350 [==============================] - 0s 976us/step - loss: 0.3745 - accuracy: 0.9359 - val_loss: 0.3729 - val_accuracy: 0.9364\n",
      "Epoch 257/300\n",
      "350/350 [==============================] - 0s 973us/step - loss: 0.3738 - accuracy: 0.9360 - val_loss: 0.3723 - val_accuracy: 0.9368\n",
      "Epoch 258/300\n",
      "350/350 [==============================] - 0s 961us/step - loss: 0.3731 - accuracy: 0.9364 - val_loss: 0.3716 - val_accuracy: 0.9368\n",
      "Epoch 259/300\n",
      "350/350 [==============================] - 0s 973us/step - loss: 0.3725 - accuracy: 0.9364 - val_loss: 0.3709 - val_accuracy: 0.9368\n",
      "Epoch 260/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3718 - accuracy: 0.9365 - val_loss: 0.3702 - val_accuracy: 0.9368\n",
      "Epoch 261/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3711 - accuracy: 0.9368 - val_loss: 0.3696 - val_accuracy: 0.9371\n",
      "Epoch 262/300\n",
      "350/350 [==============================] - 0s 932us/step - loss: 0.3704 - accuracy: 0.9375 - val_loss: 0.3689 - val_accuracy: 0.9371\n",
      "Epoch 263/300\n",
      "350/350 [==============================] - 0s 984us/step - loss: 0.3698 - accuracy: 0.9377 - val_loss: 0.3682 - val_accuracy: 0.9379\n",
      "Epoch 264/300\n",
      "350/350 [==============================] - 0s 961us/step - loss: 0.3691 - accuracy: 0.9380 - val_loss: 0.3676 - val_accuracy: 0.9379\n",
      "Epoch 265/300\n",
      "350/350 [==============================] - 0s 998us/step - loss: 0.3685 - accuracy: 0.9380 - val_loss: 0.3669 - val_accuracy: 0.9389\n",
      "Epoch 266/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3678 - accuracy: 0.9384 - val_loss: 0.3663 - val_accuracy: 0.9389\n",
      "Epoch 267/300\n",
      "350/350 [==============================] - 0s 943us/step - loss: 0.3672 - accuracy: 0.9384 - val_loss: 0.3656 - val_accuracy: 0.9393\n",
      "Epoch 268/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3666 - accuracy: 0.9387 - val_loss: 0.3650 - val_accuracy: 0.9393\n",
      "Epoch 269/300\n",
      "350/350 [==============================] - 0s 947us/step - loss: 0.3659 - accuracy: 0.9387 - val_loss: 0.3643 - val_accuracy: 0.9393\n",
      "Epoch 270/300\n",
      "350/350 [==============================] - 0s 957us/step - loss: 0.3653 - accuracy: 0.9388 - val_loss: 0.3637 - val_accuracy: 0.9393\n",
      "Epoch 271/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3647 - accuracy: 0.9391 - val_loss: 0.3631 - val_accuracy: 0.9396\n",
      "Epoch 272/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3640 - accuracy: 0.9392 - val_loss: 0.3624 - val_accuracy: 0.9396\n",
      "Epoch 273/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3634 - accuracy: 0.9396 - val_loss: 0.3618 - val_accuracy: 0.9396\n",
      "Epoch 274/300\n",
      "350/350 [==============================] - 0s 998us/step - loss: 0.3628 - accuracy: 0.9396 - val_loss: 0.3612 - val_accuracy: 0.9396\n",
      "Epoch 275/300\n",
      "350/350 [==============================] - 0s 955us/step - loss: 0.3621 - accuracy: 0.9398 - val_loss: 0.3605 - val_accuracy: 0.9396\n",
      "Epoch 276/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3615 - accuracy: 0.9404 - val_loss: 0.3599 - val_accuracy: 0.9396\n",
      "Epoch 277/300\n",
      "350/350 [==============================] - 0s 939us/step - loss: 0.3609 - accuracy: 0.9408 - val_loss: 0.3593 - val_accuracy: 0.9396\n",
      "Epoch 278/300\n",
      "350/350 [==============================] - 0s 967us/step - loss: 0.3603 - accuracy: 0.9409 - val_loss: 0.3586 - val_accuracy: 0.9414\n",
      "Epoch 279/300\n",
      "350/350 [==============================] - 0s 932us/step - loss: 0.3597 - accuracy: 0.9410 - val_loss: 0.3580 - val_accuracy: 0.9414\n",
      "Epoch 280/300\n",
      "350/350 [==============================] - 0s 946us/step - loss: 0.3590 - accuracy: 0.9413 - val_loss: 0.3574 - val_accuracy: 0.9418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/300\n",
      "350/350 [==============================] - 0s 926us/step - loss: 0.3584 - accuracy: 0.9418 - val_loss: 0.3568 - val_accuracy: 0.9425\n",
      "Epoch 282/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3578 - accuracy: 0.9421 - val_loss: 0.3562 - val_accuracy: 0.9429\n",
      "Epoch 283/300\n",
      "350/350 [==============================] - 0s 975us/step - loss: 0.3572 - accuracy: 0.9424 - val_loss: 0.3556 - val_accuracy: 0.9432\n",
      "Epoch 284/300\n",
      "350/350 [==============================] - 0s 950us/step - loss: 0.3566 - accuracy: 0.9425 - val_loss: 0.3550 - val_accuracy: 0.9432\n",
      "Epoch 285/300\n",
      "350/350 [==============================] - 0s 974us/step - loss: 0.3561 - accuracy: 0.9426 - val_loss: 0.3544 - val_accuracy: 0.9439\n",
      "Epoch 286/300\n",
      "350/350 [==============================] - 0s 946us/step - loss: 0.3555 - accuracy: 0.9427 - val_loss: 0.3538 - val_accuracy: 0.9439\n",
      "Epoch 287/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3549 - accuracy: 0.9428 - val_loss: 0.3532 - val_accuracy: 0.9439\n",
      "Epoch 288/300\n",
      "350/350 [==============================] - 0s 987us/step - loss: 0.3543 - accuracy: 0.9429 - val_loss: 0.3526 - val_accuracy: 0.9443\n",
      "Epoch 289/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3537 - accuracy: 0.9429 - val_loss: 0.3520 - val_accuracy: 0.9450\n",
      "Epoch 290/300\n",
      "350/350 [==============================] - 0s 945us/step - loss: 0.3531 - accuracy: 0.9430 - val_loss: 0.3514 - val_accuracy: 0.9454\n",
      "Epoch 291/300\n",
      "350/350 [==============================] - 0s 959us/step - loss: 0.3526 - accuracy: 0.9434 - val_loss: 0.3509 - val_accuracy: 0.9454\n",
      "Epoch 292/300\n",
      "350/350 [==============================] - 0s 963us/step - loss: 0.3520 - accuracy: 0.9436 - val_loss: 0.3503 - val_accuracy: 0.9454\n",
      "Epoch 293/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3514 - accuracy: 0.9439 - val_loss: 0.3497 - val_accuracy: 0.9468\n",
      "Epoch 294/300\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3508 - accuracy: 0.9443 - val_loss: 0.3491 - val_accuracy: 0.9468\n",
      "Epoch 295/300\n",
      "350/350 [==============================] - 0s 962us/step - loss: 0.3503 - accuracy: 0.9443 - val_loss: 0.3486 - val_accuracy: 0.9468\n",
      "Epoch 296/300\n",
      "350/350 [==============================] - 0s 929us/step - loss: 0.3497 - accuracy: 0.9446 - val_loss: 0.3480 - val_accuracy: 0.9479\n",
      "Epoch 297/300\n",
      "350/350 [==============================] - 0s 975us/step - loss: 0.3492 - accuracy: 0.9449 - val_loss: 0.3474 - val_accuracy: 0.9482\n",
      "Epoch 298/300\n",
      "350/350 [==============================] - 0s 942us/step - loss: 0.3486 - accuracy: 0.9454 - val_loss: 0.3469 - val_accuracy: 0.9482\n",
      "Epoch 299/300\n",
      "350/350 [==============================] - 0s 970us/step - loss: 0.3480 - accuracy: 0.9450 - val_loss: 0.3463 - val_accuracy: 0.9482\n",
      "Epoch 300/300\n",
      "350/350 [==============================] - 0s 967us/step - loss: 0.3475 - accuracy: 0.9455 - val_loss: 0.3458 - val_accuracy: 0.9482\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c7c00a79d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model\n",
    "model = Sequential()\n",
    "\n",
    "# Layer 추가\n",
    "model.add(Flatten(input_shape=(2, )))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Model 설정\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "# loss에서의 sparse_\n",
    "#     알아서 onehot으로 변경시켜서 동작한다.\n",
    "\n",
    "# Model 학습\n",
    "model.fit(x_data_train_norm,\n",
    "         t_data_train,\n",
    "         epochs=300,\n",
    "         validation_split=0.2,\n",
    "         verbose=1)\n",
    "\n",
    "# 출력\n",
    "# Epoch 1/300\n",
    "# 350/350 [==============================] - 1s 1ms/step - loss: 1.0162 - accuracy: 0.4326 - val_loss: 1.0088 - val_accuracy: 0.4614\n",
    "# Epoch 300/300\n",
    "# 350/350 [==============================] - 0s 967us/step - loss: 0.3475 - accuracy: 0.9455 - val_loss: 0.3458 - val_accuracy: 0.9482\n",
    "# <keras.callbacks.History at 0x2c7c00a79d0>\n",
    "\n",
    "# loss, accuracy : 학습 데이터로 만든 결과물. 크게 중요치 않은 데이터.\n",
    "# val_loss, val_accuracy : 중간중간 테스트데이터로 검증받은 확률. 이게 중요한 데이터다.\n",
    "#     val_loss : loss니까 낮을 수록 좋은 결과\n",
    "#     val_accuracy : 정확도. 높을 수록 좋다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5320472f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 0s 707us/step - loss: 0.2742 - accuracy: 0.9707\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2741805911064148, 0.9706666469573975]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델의 evaluation(평가) 진행\n",
    "model.evaluate(x_data_test_norm, t_data_test_onehot)\n",
    "# 출력\n",
    "#     188/188 [==============================] - 0s 633us/step - loss: 0.2742 - accuracy: 0.9707\n",
    "#     [0.2741805911064148, 0.9706666469573975]\n",
    "#     [최종 loss값, 최종 accuracy값]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9fbc0ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.02958116 0.6650098  0.30540907]]\n"
     ]
    }
   ],
   "source": [
    "# 예측\n",
    "predict_data = np.array([[180, 76]])\n",
    "scaled_predict_data = scaler.transform(predict_data)\n",
    "print(model.predict(scaled_predict_data))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_env] *",
   "language": "python",
   "name": "conda-env-data_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
